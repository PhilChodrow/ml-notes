@book{abu-mostafaLearningDataShort2012,
  title = {Learning from Data: A Short Course},
  shorttitle = {Learning from Data},
  author = {{Abu-Mostafa}, Yaser S. and {Magdon-Ismail}, Malik and Lin, Hsuan-Tien},
  year = {2012},
  address = {{S.l.}},
  url = {https://amlbook.com/},
  isbn = {978-1-60049-006-4},
  langid = {english},
  file = {/Users/philchodrow/Zotero/storage/LF6LK5RU/Abu-Mostafa Yaser S., Malik Magdon-Ismail, Hsuan-Tien Lin (2012) -- Learning From Data_ A short course.pdf}
}

@incollection{angwin2022machine,
  title = {Machine Bias},
  booktitle = {Ethics of Data and Analytics},
  author = {Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
  year = {2022},
  pages = {254--264},
  publisher = {{Auerbach Publications}}
}

@article{bak-colemanStewardshipGlobalCollective2021,
  title = {Stewardship of Global Collective Behavior},
  author = {{Bak-Coleman}, Joseph B. and Alfano, Mark and Barfuss, Wolfram and Bergstrom, Carl T. and Centeno, Miguel A. and Couzin, Iain D. and Donges, Jonathan F. and Galesic, Mirta and Gersick, Andrew S. and Jacquet, Jennifer and Kao, Albert B. and Moran, Rachel E. and Romanczuk, Pawel and Rubenstein, Daniel I. and Tombak, Kaia J. and Van Bavel, Jay J. and Weber, Elke U.},
  year = {2021},
  month = jul,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {27},
  pages = {e2025764118},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2025764118},
  url = {https://pnas.org/doi/full/10.1073/pnas.2025764118},
  urldate = {2022-05-16},
  abstract = {Collective behavior provides a framework for understanding how the actions and properties of groups emerge from the way individuals generate and share information. In humans, information flows were initially shaped by natural selection yet are increasingly structured by emerging communication technologies. Our larger, more complex social networks now transfer high-fidelity information over vast distances at low cost. The digital age and the rise of social media have accelerated changes to our social systems, with poorly understood functional consequences. This gap in our knowledge represents a principal challenge to scientific progress, democracy, and actions to address global crises. We argue that the study of collective behavior must rise to a ``crisis discipline'' just as medicine, conservation, and climate science have, with a focus on providing actionable insight to policymakers and regulators for the stewardship of social systems.},
  langid = {english},
  file = {/Users/philchodrow/Zotero/storage/9B9AC8BX/Bak-Coleman et al. - 2021 - Stewardship of global collective behavior.pdf}
}

@book{barocasFairnessMachineLearning2023,
  title = {Fairness and Machine Learning: Limitations and Opportunities},
  shorttitle = {Fairness and Machine Learning},
  author = {Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
  year = {2023},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  url = {https://fairmlbook.org/pdf/fairmlbook.pdf},
  abstract = {"This book offers a critical view on the current practice of machine learning, as well as proposed technical fixes for achieving fairness in automated decisionmaking"--},
  isbn = {978-0-262-04861-3},
  lccn = {Q325.5 .B36 2023},
  keywords = {Automation,Decision making,Discrimination,Human factors,Law and legislation,Machine learning,Moral and ethical aspects,United States},
  file = {/Users/philchodrow/Zotero/storage/BSQALENF/fairmlbook.pdf}
}

@book{bishopPatternRecognitionMachine2006,
  title = {Pattern {{Recognition}} and {{Machine Learning}}},
  author = {Bishop, Christopher M.},
  year = {2006},
  series = {Information Science and Statistics},
  publisher = {{Springer}},
  address = {{New York}},
  url = {https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf},
  isbn = {978-0-387-31073-2},
  lccn = {Q327 .B52 2006},
  keywords = {Machine learning,Pattern perception}
}

@book{deisenrothMathematicsMachineLearning2020,
  title = {Mathematics for Machine Learning},
  author = {Deisenroth, Marc Peter and Faisal, A. Aldo and Ong, Cheng Soon},
  year = {2020},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, UK New York, NY}},
  url = {https://mml-book.github.io/book/mml-book.pdf},
  abstract = {"The fundamental mathematical tools needed to understand machine learning include linear algebra, analytic geometry, matrix decompositions, vector calculus, optimization, probability, and statistics. These topics are traditionally taught in disparate courses, making it hard for data science or computer science students, or professionals, to efficiently learn the mathematics. This self-contained textbook bridges the gap between mathematical and machine learning texts, introducing the mathematical concepts with a minimum of prerequisites. It uses these concepts to derive four central machine learning methods: linear regression, principal component analysis, Gaussian mixture models, and support vector machines. For students and others with a mathematical background, these derivations provide a starting point to machine learning texts. For those learning the mathematics for the first time, the methods help build intuition and practical experience with applying mathematical concepts"},
  isbn = {978-1-108-47004-9 978-1-108-45514-5},
  langid = {english},
  lccn = {006.31},
  file = {/Users/philchodrow/Zotero/storage/BY2YT3SE/mml-book.pdf}
}

@article{gormanEcologicalSexualDimorphism2014,
  title = {Ecological {{Sexual Dimorphism}} and {{Environmental Variability}} within a {{Community}} of {{Antarctic Penguins}} ({{Genus Pygoscelis}})},
  author = {Gorman, Kristen B. and Williams, Tony D. and Fraser, William R.},
  editor = {Chiaradia, Andr{\'e}},
  year = {2014},
  month = mar,
  journal = {PLoS ONE},
  volume = {9},
  number = {3},
  pages = {e90081},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0090081},
  url = {https://dx.plos.org/10.1371/journal.pone.0090081},
  urldate = {2024-01-17},
  langid = {english},
  file = {/Users/philchodrow/Zotero/storage/J7LBCFE6/Gorman et al. - 2014 - Ecological Sexual Dimorphism and Environmental Var.pdf}
}

@book{hardtPatternsPredictionsActions2022,
  title = {Patterns, {{Predictions}}, and {{Actions}}},
  author = {Hardt, Moritz and Recht, Benjamin},
  year = {2022},
  publisher = {{Princeton University Press}},
  url = {https://mlstory.org/pdf/patterns.pdf},
  isbn = {978-0-691-23372-7},
  langid = {english},
  file = {/Users/philchodrow/Zotero/storage/44JG3327/Hardt and Recht - Patterns, Predictions, and Actions.pdf}
}

@book{hastieElementsStatisticalLearning2017,
  title = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  shorttitle = {The Elements of Statistical Learning},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H.},
  year = {2017},
  series = {Springer Series in Statistics},
  edition = {Second edition, corrected at 12th printing 2017},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/b94608},
  url = {https://hastie.su.domains/Papers/ESLII.pdf},
  isbn = {978-0-387-84857-0},
  langid = {english},
  file = {/Users/philchodrow/Zotero/storage/FW5KENHU/Hastie et al. - 2017 - The elements of statistical learning data mining,.pdf}
}

@misc{horstAllisonhorstPalmerpenguinsV02020,
  title = {Allisonhorst/Palmerpenguins: V0.1.0},
  shorttitle = {Allisonhorst/Palmerpenguins},
  author = {Horst, Allison M and Hill, Alison Presmanes and Gorman, Kristen B},
  year = {2020},
  month = jul,
  doi = {10.5281/ZENODO.3960218},
  url = {https://zenodo.org/record/3960218},
  urldate = {2024-01-17},
  abstract = {CRAN release of palmerpenguins v0.1.0 R package by Horst, Hill and Gorman (July 2020).},
  copyright = {Open Access},
  howpublished = {Zenodo}
}

@inproceedings{kingma2015adam,
  title = {Adam: {{A}} Method for Stochastic Gradient Descent},
  booktitle = {{{ICLR}}: International Conference on Learning Representations},
  author = {Kingma, Diederik P and Ba, Jimmy Lei},
  year = {2015},
  pages = {1--15},
  publisher = {{ICLR US.}}
}

@book{kroeseDataScienceMachine2020,
  title = {Data Science and Machine Learning: Mathematical and Statistical Methods},
  shorttitle = {Data Science and Machine Learning},
  author = {Kroese, Dirk P. and Botev, Zdravko I. and Taimre, Thomas and Vaisman, Radislav},
  year = {2020},
  series = {Chapman \& {{Hall}}/{{CRC}} Machine Learning \& Pattern Recognition Series},
  publisher = {{CRC Press, Taylor \& Francis Group}},
  address = {{Boca Raton London New York}},
  isbn = {978-1-138-49253-0},
  langid = {english},
  file = {/Users/philchodrow/Zotero/storage/PRWRZWR7/DSML.pdf}
}

@article{mehrabiSurveyBiasFairness2021,
  title = {A {{Survey}} on {{Bias}} and {{Fairness}} in {{Machine Learning}}},
  author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  year = {2021},
  month = jul,
  journal = {ACM Computing Surveys},
  volume = {54},
  number = {6},
  pages = {1--35},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3457607},
  url = {https://dl.acm.org/doi/10.1145/3457607},
  urldate = {2022-11-11},
  abstract = {With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
  langid = {english},
  file = {/Users/philchodrow/Zotero/storage/APRDZTJ3/Mehrabi et al. - 2021 - A Survey on Bias and Fairness in Machine Learning.pdf}
}

@book{murphyProbabilisticMachineLearning2022a,
  title = {Probabilistic Machine Learning: An Introduction},
  shorttitle = {Probabilistic Machine Learning},
  author = {Murphy, Kevin P.},
  year = {2022},
  series = {Adaptive Computation and Machine Learning Series},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  url = {https://probml.github.io/pml-book/book1.html},
  abstract = {"This book provides a detailed and up-to-date coverage of machine learning. It is unique in that it unifies approaches based on deep learning with approaches based on probabilistic modeling and inference. It provides mathematical background (e.g. linear algebra, optimization), basic topics (e.g., linear and logistic regression, deep neural networks), as well as more advanced topics (e.g., Gaussian processes). It provides a perfect introduction for people who want to understand cutting edge work in top machine learning conferences such as NeurIPS, ICML and ICLR"--},
  isbn = {978-0-262-04682-4},
  lccn = {Q325.5 .M872 2022},
  keywords = {Machine learning,Probabilities},
  file = {/Users/philchodrow/Zotero/storage/SFJ9XXZT/book1.pdf}
}

@misc{narayanan2022limits,
  title = {The Limits of the Quantitative Approach to Discrimination},
  author = {Narayanan, Arvind},
  year = {2022},
  howpublished = {Speech}
}

@article{obermeyerDissectingRacialBias2019b,
  title = {Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations},
  author = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  year = {2019},
  month = oct,
  journal = {Science},
  volume = {366},
  number = {6464},
  pages = {447--453},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aax2342},
  url = {https://www.science.org/doi/10.1126/science.aax2342},
  urldate = {2024-02-05},
  abstract = {Racial bias in health algorithms                            The U.S. health care system uses commercial algorithms to guide health decisions. Obermeyer               et al.               find evidence of racial bias in one widely used algorithm, such that Black patients assigned the same level of risk by the algorithm are sicker than White patients (see the Perspective by Benjamin). The authors estimated that this racial bias reduces the number of Black patients identified for extra care by more than half. Bias occurs because the algorithm uses health costs as a proxy for health needs. Less money is spent on Black patients who have the same level of need, and the algorithm thus falsely concludes that Black patients are healthier than equally sick White patients. Reformulating the algorithm so that it no longer uses costs as a proxy for needs eliminates the racial bias in predicting who needs extra care.                                         Science               , this issue p.               447               ; see also p.               421                        ,              A health algorithm that uses health costs as a proxy for health needs leads to racial bias against Black patients.           ,              Health systems rely on commercial prediction algorithms to identify and help patients with complex health needs. We show that a widely used algorithm, typical of this industry-wide approach and affecting millions of patients, exhibits significant racial bias: At a given risk score, Black patients are considerably sicker than White patients, as evidenced by signs of uncontrolled illnesses. Remedying this disparity would increase the percentage of Black patients receiving additional help from 17.7 to 46.5\%. The bias arises because the algorithm predicts health care costs rather than illness, but unequal access to care means that we spend less money caring for Black patients than for White patients. Thus, despite health care cost appearing to be an effective proxy for health by some measures of predictive accuracy, large racial biases arise. We suggest that the choice of convenient, seemingly effective proxies for ground truth can be an important source of algorithmic bias in many contexts.},
  langid = {english},
  file = {/Users/philchodrow/Zotero/storage/I4PDP3YW/Obermeyer et al. - 2019 - Dissecting racial bias in an algorithm used to man.pdf}
}

@article{stiglerEpicStoryMaximum2007,
  title = {The {{Epic Story}} of {{Maximum Likelihood}}},
  author = {Stigler, Stephen M.},
  year = {2007},
  month = nov,
  journal = {Statistical Science},
  volume = {22},
  number = {4},
  eprint = {0804.2996},
  primaryclass = {stat},
  issn = {0883-4237},
  doi = {10.1214/07-STS249},
  url = {http://arxiv.org/abs/0804.2996},
  urldate = {2023-01-31},
  abstract = {At a superficial level, the idea of maximum likelihood must be prehistoric: early hunters and gatherers may not have used the words ``method of maximum likelihood'' to describe their choice of where and how to hunt and gather, but it is hard to believe they would have been surprised if their method had been described in those terms. It seems a simple, even unassailable idea: Who would rise to argue in favor of a method of minimum likelihood, or even mediocre likelihood? And yet the mathematical history of the topic shows this ``simple idea'' is really anything but simple. Joseph Louis Lagrange, Daniel Bernoulli, Leonard Euler, Pierre Simon Laplace and Carl Friedrich Gauss are only some of those who explored the topic, not always in ways we would sanction today. In this article, that history is reviewed from back well before Fisher to the time of Lucien Le Cam's dissertation. In the process Fisher's unpublished 1930 characterization of conditions for the consistency and efficiency of maximum likelihood estimates is presented, and the mathematical basis of his three proofs discussed. In particular, Fisher's derivation of the information inequality is seen to be derived from his work on the analysis of variance, and his later approach via estimating functions was derived from Euler's Relation for homogeneous functions. The reaction to Fisher's work is reviewed, and some lessons drawn.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Methodology},
  file = {/Users/philchodrow/Zotero/storage/97IZKFI9/Stigler - 2007 - The Epic Story of Maximum Likelihood.pdf;/Users/philchodrow/Zotero/storage/9FDAVVQ3/0804.html}
}

@book{vanderplasPythonDataScience2016,
  title = {Python Data Science Handbook: Essential Tools for Working with Data},
  shorttitle = {Python Data Science Handbook},
  author = {Vanderplas, Jacob T.},
  year = {2016},
  edition = {First edition},
  publisher = {{O'Reilly Media, Inc}},
  address = {{Sebastopol, CA}},
  isbn = {978-1-4919-1205-8},
  lccn = {QA76.73.P98 V365 2016},
  keywords = {Data mining,Data Mining,Datenanalyse,Datenmanagement,Python,Python (Computer program language)},
  annotation = {OCLC: ocn915498936}
}

@article{wickhamSplitApplyCombineStrategyData2011,
  title = {The {{Split-Apply-Combine Strategy}} for {{Data Analysis}}},
  author = {Wickham, Hadley},
  year = {2011},
  journal = {Journal of Statistical Software},
  volume = {40},
  number = {1},
  issn = {1548-7660},
  doi = {10.18637/jss.v040.i01},
  url = {http://www.jstatsoft.org/v40/i01/},
  urldate = {2024-02-01},
  langid = {english},
  file = {/Users/philchodrow/Zotero/storage/GWGH5IMN/Wickham - 2011 - The Split-Apply-Combine Strategy for Data Analysis.pdf}
}

@book{zhangDiveDeepLearning2023,
  title = {Dive into Deep Learning},
  author = {Zhang, Aston and Lipton, Zachary and Li, Mu},
  year = {2023},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, UK}},
  isbn = {978-1-00-938943-3},
  langid = {english},
  annotation = {OCLC: 1403378564},
  file = {/Users/philchodrow/Zotero/storage/S5S23QCB/d2l-en.pdf}
}
