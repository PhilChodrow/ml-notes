<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8" />
<meta name="generator" content="quarto-1.6.10" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />


<title>4  Decision Theory in Classification – Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<!-- htmldependencies:E3FAD763 -->
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css" />
</head>

<body>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn"
      data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" 
      aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation"
      onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <h1 class="quarto-secondary-nav-title no-breadcrumbs"></h1>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" role="link"
        aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation"
        onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="/">
      Machine Learning
      </a> 
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1"  role="navigation" aria-expanded="true">
 <span class="menu-text">Introducing Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/01-data-and-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>1</span>  <span class='chapter-title'>Data, Patterns, and Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/02-black-box-classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>2</span>  <span class='chapter-title'>Classification as a Black Box</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2"  role="navigation" aria-expanded="true">
 <span class="menu-text">Fundamentals of Prediction</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/03-score-based-classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>3</span>  <span class='chapter-title'>Score-Based Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/04-decision-theory.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class='chapter-number'>4</span>  <span class='chapter-title'>Decision Theory in Classification</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3"  role="navigation" aria-expanded="true">
 <span class="menu-text">Discrimination, Disparity, Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/10-compas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Algorithmic Disparity: COMPAS</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/12-statistical-fairness.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>6</span>  <span class='chapter-title'>Statistical Definitions of Fairness in Decision-Making</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4"  role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/20-perceptron.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to Classification: The Perceptron</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/22-convex-erm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>8</span>  <span class='chapter-title'>Convex Empirical Risk Minimization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/23-gradient-descent.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>9</span>  <span class='chapter-title'>Optimization with Gradient Descent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/30-features-regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>10</span>  <span class='chapter-title'>Feature Maps, Regularization, and Generalization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/40-linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>11</span>  <span class='chapter-title'>Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/50-kernel-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>12</span>  <span class='chapter-title'>Kernel Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/51-vectorization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>13</span>  <span class='chapter-title'>Vectorization and Feature Engineering</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5"  role="navigation" aria-expanded="true">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/60-intro-deep.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>14</span>  <span class='chapter-title'>The Problem of Features and Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/61-modern-optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>15</span>  <span class='chapter-title'>Contemporary Optimization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/70-image-classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>16</span>  <span class='chapter-title'>Deep Image Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/72-text-classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>17</span>  <span class='chapter-title'>Text Classification and Word Embedding</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6"  role="navigation" aria-expanded="true">
 <span class="menu-text">Unsupervised Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/80-unsupervised-autoencoders.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>18</span>  <span class='chapter-title'>Unsupervised Learning and Autoencoders</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/source/81-neural-autoencoders.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>19</span>  <span class='chapter-title'>Neural Autoencoders and Dimensionality Reduction</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" ></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <div id="quarto-toc-target"></div>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">4</span>  <span class="chapter-title">Decision Theory in Classification</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>

<nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#last-time" id="toc-last-time">Last time…</a></li>
  <li><a href="#lending-data-set" id="toc-lending-data-set">Lending Data Set</a></li>
  <li><a href="#vectorized-computation-of-scores" id="toc-vectorized-computation-of-scores">Vectorized Computation of Scores</a></li>
  <li><a href="#types-of-error" id="toc-types-of-error">Types of Error</a>
  <ul>
  <li><a href="#the-roc-curve" id="toc-the-roc-curve">The ROC Curve</a></li>
  <li><a href="#cost-of-errors-and-optimal-thresholding" id="toc-cost-of-errors-and-optimal-thresholding">Cost of Errors and Optimal Thresholding</a></li>
  </ul></li>
  <li><a href="#recap" id="toc-recap">Recap</a></li>
  <li><a href="#who-sets-the-cost-who-pays-the-cost" id="toc-who-sets-the-cost-who-pays-the-cost">Who Sets The Cost? Who Pays the Cost?</a></li>
  </ul>
</nav>
<p>Machine learning algorithms are often used to make recommendations to inform decisions:</p>
<ul>
<li>Should a patient receive additional confirmatory screening for a rare disease?</li>
<li>Should an email be sent to the spam folder, or should it be sent to the primary inbox?</li>
<li>Should a prospective borrower be granted a loan?</li>
</ul>
<p>An important feature of each of these examples is that there may be <em>asymmetric costs of error</em>. In many cases, it’s worse to be wrong in one way than it is to be wrong in another. A patient who in fact <em>has</em> a rare disease but <em>is not</em> screened for it is at grave risk, while a patient who <em>does not</em> have a rare disease but <em>is</em> screened for it might only risk a higher bill. A frivolous email sent to the main inbox is an irritation, while an important email sent to the spam folder is an opportunity for consequential miscommunication. A prospective borrower who <em>is</em> granted a loan but <em>should not</em> have been granted a loan may default and lose money for the lender, while a prospective borrower who <em>is not</em> granted a loan but <em>should</em> have been granted a loan cannot default and therefore cannot incur losses for the lender.</p>
<p>In cases with asymmetric costs of error, selecting models based on <em>accuracy</em> may not be the right approach, since accuracy treats all types of error as equally weighty. In this set of notes, we’ll go beyond accuracy and learn how to tune models for decision-making in the presence of asymmetric error costs.</p>
<p>We are going to <em>operationalize</em> this via the choice of the threshold <span class="math inline">\(t\)</span> in the score-based classification framework that we discussed <a href="03-score-based-classification.qmd">last time</a>. Let’s do a quick recap:</p>
<section id="last-time" class="level2">
<h2>Last time…</h2>
<p>…we considered a prediction problem in which we observed <span class="math inline">\(p\)</span> attributes of prospective borrower <span class="math inline">\(i\)</span> in the form of a vector <span class="math inline">\(\mathbf{x}_i \in \mathbb{R}^p\)</span>. We then formed a <em>score</em> for prospective borrower <span class="math inline">\(i\)</span> using a weight vector <span class="math inline">\(\mathbf{w}\in \mathbb{R}^p\)</span> and an inner product:</p>
<p><span class="column-margin margin-aside">We also developed the ability to compute nonlinear scores by instead computing the score as <span class="math inline">\(s_i = \langle \mathbf{w},\phi(\mathbf{x}_i) \rangle\)</span>, where <span class="math inline">\(\phi\)</span> was a <strong>feature map</strong> that computed nonlinear functions of the entries of <span class="math inline">\(\mathbf{x}_i\)</span>. For reasons that we’ll learn about when we study the theory of machine learning, this is <em>still</em> called a linear model, due to the fact that the score is a linear function of the vector <span class="math inline">\(\mathbf{w}\)</span>. In this set of notes, we’ll always assume that <span class="math inline">\(\mathbf{x}\)</span> has <em>already</em> had a feature map applied to it, so that we can just focus on the simpler form of <a href="#eq-linear-model" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-linear-model</span></a>.</span></p>
<p><span id="eq-linear-model"><span class="math display">\[
\begin{aligned}
    s_i = \langle \mathbf{x}_i, \mathbf{w}  \rangle\;.
\end{aligned}
\tag{4.1}\]</span></span></p>
<p>Then, we <em>classified</em> prospective borrowers into two categories based on a threshold <span class="math inline">\(t \in \mathbb{R}\)</span>:</p>
<ul>
<li>Borrowers who receive a loan had the property <span class="math inline">\(s_i \leq t\)</span>.</li>
<li>Borrowers who do not receive a loan have the property <span class="math inline">\(s_i &gt; t\)</span>.</li>
</ul>
<p><a href="#eq-linear-model" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-linear-model</span></a> says that the score should be computed as a <em>linear function</em> of the features <span class="math inline">\(\mathbf{x}_i\)</span>. Models with this property are called <em>linear models</em> and are fundamental in both classification and regression tasks.</p>
</section>
<section id="lending-data-set" class="level2">
<h2>Lending Data Set</h2>
<p>To illustrate our discussion, we are going to pull up the lending data set from the previous section. <span class="column-margin margin-aside">This hidden code cell imports several standard Python libraries and reads in our data, saving the result in a variable called <code>df</code>.</span></p>
<div id="f2260aa9" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode" id="cb1"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>pd.options.mode.chained_assignment <span class="op">=</span> <span class="va">None</span>  </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>np.set_printoptions(precision <span class="op">=</span> <span class="dv">3</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">&#39;seaborn-v0_8-whitegrid&#39;</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">&quot;https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/credit_risk_dataset.csv&quot;</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>df_all <span class="op">=</span> pd.read_csv(url)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df_all[[<span class="st">&quot;loan_int_rate&quot;</span>, <span class="st">&quot;loan_percent_income&quot;</span>, <span class="st">&quot;loan_status&quot;</span>]]</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.dropna()</span></code></pre></div>
</details>
</div>
<p>Following the usual paradigm in machine learning, we’re going to incorporate two elements which we previously saw <a href="../source/02-black-box-classification.qmd">when studying the Palmer penguins</a>. First, we are going to hold off a part of our data set that we will not use for making any choices about how we design our decision algorithm. This held-off part of the data is called the <em>test set</em>. We’ll use it for a final evaluation of our model’s performance.</p>
<div id="cbffb3fa" class="cell" data-execution_count="2">
<div class="sourceCode" id="cb2"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df_train, df_test <span class="op">=</span> train_test_split(df, test_size <span class="op">=</span> <span class="fl">0.2</span>, random_state <span class="op">=</span> <span class="dv">123</span>) <span class="co"># 20% test set</span></span></code></pre></div>
</div>
<p>Next, we’ll distinguish our predictor and target variables in each of the train and test sets.</p>
<div id="b88f67cf" class="cell" data-execution_count="3">
<div class="sourceCode" id="cb3"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> df_train[[<span class="st">&quot;loan_int_rate&quot;</span>, <span class="st">&quot;loan_percent_income&quot;</span>]]</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> df_train[<span class="st">&quot;loan_status&quot;</span>]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> df_test[[<span class="st">&quot;loan_int_rate&quot;</span>, <span class="st">&quot;loan_percent_income&quot;</span>]]</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> df_test[<span class="st">&quot;loan_status&quot;</span>]</span></code></pre></div>
</div>
<p>Now we’re ready to proceed in making predictions and comparing our predictions to outcomes in both the training and test sets.</p>
</section>
<section id="vectorized-computation-of-scores" class="level2">
<h2>Vectorized Computation of Scores</h2>
<p>Suppose that we have a weight vector <span class="math inline">\(\mathbf{w}\)</span> and that we’d like to choose a threshold <span class="math inline">\(t\)</span>. To do this, we will compute all the scores on the training data and do some experiments. How should we compute training scores? As we know, the <span class="math inline">\(i\)</span>th score is given by <a href="#eq-linear-model" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-linear-model</span></a>. To compute scores for all <span class="math inline">\(n\)</span> of our training points, we could write a loop like this: <span class="column-margin margin-aside">In our case, <span class="math inline">\(n =\)</span> 23572, the number of rows in the training data.</span></p>
<div id="044a61f9" class="cell" data-execution_count="4">
<div class="sourceCode" id="cb4"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> df_train.shape[<span class="dv">0</span>]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> [] <span class="co"># vector of scores</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    s.append(compute_score(X[i], w))</span></code></pre></div>
</div>
<p>where <code>X[i]</code> is the <code>i</code>th data point <span class="math inline">\(\mathbf{x}_i\)</span> and <code>compute_score</code> is a function that computes the score according to <a href="#eq-linear-model" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-linear-model</span></a>. However, there’s a better way to do this if we step back from code into math for a moment. If <span class="math inline">\(\mathbf{s} \in \mathbb{R}^n\)</span> is a vector whose <span class="math inline">\(i\)</span>th entry is the score <span class="math inline">\(s_i\)</span>, then we have</p>
<p><span class="math display">\[
\begin{aligned}
    \mathbf{s} = \left(
        \begin{matrix}
            \langle \mathbf{x}_1, \mathbf{w} \rangle \\
            \langle \mathbf{x}_2, \mathbf{w} \rangle \\
            \vdots \\
            \langle \mathbf{x}_n, \mathbf{w} \rangle
        \end{matrix}
        \right) = \mathbf{X}\mathbf{w}\;,
\end{aligned}
\]</span></p>
<p>where we have defined the <em>predictor matrix</em> <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{n \times p}\)</span></p>
<p><span class="math display">\[
\begin{aligned}
    \mathbf{X} = \left[
        \begin{matrix}
            \rule[.5ex]{2.5ex}{0.5pt} \; \mathbf{x}_1 \;\rule[.5ex]{2.5ex}{0.5pt}  \\
            \rule[.5ex]{2.5ex}{0.5pt}\;\mathbf{x}_2 \; \rule[.5ex]{2.5ex}{0.5pt}  \\
            \vdots \\
            \rule[.5ex]{2.5ex}{0.5pt} \;  \mathbf{x}_n \;\rule[.5ex]{2.5ex}{0.5pt}
        \end{matrix}
        \right] =
        \left[
        \begin{matrix}
            x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \\
            x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\
            \vdots \\
            x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
        \end{matrix}
        \right]\;.
\end{aligned}
\]</span></p>
<p>This is good news because it simplifies our life both mathematically and in code: the Numpy package supplies very fast matrix multiplication:</p>
<div id="151e7cdb" class="cell" data-execution_count="5">
<div class="sourceCode" id="cb5"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> linear_score(X, w):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X<span class="op">@</span>w</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span></code></pre></div>
</div>
<p>Now, given <span class="math inline">\(\mathbf{w}\)</span>, we can compute all the scores at once. To do this, we’ll finally choose a value for <span class="math inline">\(\mathbf{w}\)</span>: <span class="column-margin margin-aside">Again, the topic of <em>how to choose <span class="math inline">\(\mathbf{w}\)</span> is the topic of </em>model training*, which we’ll study in detail soon.</span></p>
<div id="f8571a9d" class="cell" data-execution_count="6">
<div class="sourceCode" id="cb6"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> np.array([<span class="fl">0.01</span>, <span class="fl">1.0</span>])</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> linear_score(X_train, w)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span></code></pre></div>
</div>
<p>Importantly, we were able to compute all of our scores on the training data without writing any loops. This is both easier for us to read/write and much faster for most computers to execute; the reason is that Numpy is able to use highly optimized C code to perform the matrix multiplication.</p>
<p>Here is a histogram of the scores we just computed:</p>
<div id="7e7a6843" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode" id="cb7"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize <span class="op">=</span> (<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> ax.hist(s, bins <span class="op">=</span> <span class="dv">50</span>, color <span class="op">=</span> <span class="st">&quot;steelblue&quot;</span>, alpha <span class="op">=</span> <span class="fl">0.6</span>, linewidth <span class="op">=</span> <span class="dv">1</span>, edgecolor <span class="op">=</span> <span class="st">&quot;black&quot;</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>labs <span class="op">=</span> ax.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="vs">r&quot;Score $s$&quot;</span>, ylabel <span class="op">=</span> <span class="st">&quot;Frequency&quot;</span>) </span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img src="04-decision-theory_files/figure-html/cell-8-output-1.png" class="margin-caption" width="517" height="349" /></p>
</figure>
</div>
</div>
</div>
<p>We see that most of the scores are relatively small, but that a small number of scores are over <span class="math inline">\(0.5\)</span>. Numpy offers many helpful vectorized operations which make it quick to answer simple questions about the data. For example, what proportion of scores are larger than <span class="math inline">\(0.5\)</span>?</p>
<div id="88aa4f9f" class="cell" data-execution_count="8">
<div class="sourceCode" id="cb8"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>(s <span class="op">&gt;</span> <span class="fl">0.5</span>).mean()</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span></code></pre></div>
<div class="cell-output cell-output-display margin-caption" data-execution_count="133">
<pre><code>0.050398778211437296</code></pre>
</div>
</div>
</section>
<section id="types-of-error" class="level2">
<h2>Types of Error</h2>
<p>Once we have a vector of scores <span class="math inline">\(\mathbf{s}\)</span>, we can create a vector of <em>predictions</em> simply by applying a threshold <span class="math inline">\(t\)</span>. Here’s our training predictions for the loan data using a threshold <span class="math inline">\(t = 0.4\)</span>: <span class="column-margin margin-aside">Recall that a prediction of <code>True</code> means that the individual is considered likely to default on their loan and therefore should <em>not</em> be offered credit.</span></p>
<div id="406641ad" class="cell" data-execution_count="9">
<div class="sourceCode" id="cb10"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> <span class="fl">0.4</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> s <span class="op">&gt;=</span> t</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>preds.head()</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span></code></pre></div>
<div class="cell-output cell-output-display margin-caption" data-execution_count="134">
<pre><code>17279    False
14157     True
25427    False
23449     True
14739     True
dtype: bool</code></pre>
</div>
</div>
<p>What proportion of individuals are predicted to default?</p>
<div id="ede0359c" class="cell" data-execution_count="10">
<div class="sourceCode" id="cb12"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>preds.mean()</span></code></pre></div>
<div class="cell-output cell-output-display margin-caption" data-execution_count="135">
<pre><code>0.15386899711522145</code></pre>
</div>
</div>
<p>Of course, this result depends strongly on our choice of threshold <span class="math inline">\(t\)</span>. How should we choose it? One possibility would be to try to choose the threshold in a way that maximizes the training accuracy, the number of times that the prediction agrees with the actual outcome (repaid or default) on the training data. Here’s an example of a quick grid search:</p>
<div id="48e29567" class="cell" data-execution_count="11">
<div class="sourceCode" id="cb14"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>best_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>best_threshold <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize <span class="op">=</span> (<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">101</span>): </span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> s <span class="op">&gt;=</span> t</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> (y_pred <span class="op">==</span> y_train).mean()</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    ax.scatter(t, acc, color <span class="op">=</span> <span class="st">&quot;steelblue&quot;</span>, s <span class="op">=</span> <span class="dv">10</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> acc <span class="op">&gt;</span> best_accuracy: </span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        best_accuracy <span class="op">=</span> acc</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        best_threshold <span class="op">=</span> t</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>ax.axvline(best_threshold, linestyle <span class="op">=</span> <span class="st">&quot;--&quot;</span>, color <span class="op">=</span> <span class="st">&quot;grey&quot;</span>, zorder <span class="op">=</span> <span class="op">-</span><span class="dv">10</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>labs <span class="op">=</span> ax.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="vs">r&quot;Threshold $t$&quot;</span>, ylabel <span class="op">=</span> <span class="st">&quot;Accuracy&quot;</span>, title <span class="op">=</span> <span class="ss">f&quot;Best accuracy </span><span class="sc">{</span>best_accuracy<span class="sc">:.3f}</span><span class="ss"> at best threshold t = </span><span class="sc">{</span>best_threshold<span class="sc">:.3f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img src="04-decision-theory_files/figure-html/cell-12-output-1.png" class="margin-caption" width="506" height="368" /></p>
</figure>
</div>
</div>
</div>
<p>However, accuracy is not always the most relevant measure. For example, <a href="https://www.fieldandstream.com/survival/how-many-shark-attacks-per-year/#:~:text=In%20recent%20years%2C%20there&#39;s%20been,%E2%80%94a%2010%2Dyear%20low.">Field and Stream estimates</a> that there are, globally, approximately 70 unprovoked shark attacks each year. Since the population of the world is currently around <span class="math inline">\(8.1\times 10^9\)</span> people, the average probability that a specific individual will suffer an unprovoked shark attack in a year is approximately <span class="math inline">\(70 / (8.1 \times 10^9) \approx 8.6 \times 10^{-9}\)</span>. So, if we created a shark attack predictor which always predicted “no shark attack,” our model would be correct approximately 99.999999% of the time. However, this model wouldn’t be very <em>useful</em>, and wouldn’t have anything to tell us about the activities that increase or reduce the risk of experience an attack.</p>
<p>A second reason we may wish to measure something other than accuracy has to do with <em>asymmetrical costs of error</em>. If we incorrectly predict that an individual will suffer a shark attack but no attack occurs, this is not that big a problem. Yes, we were wrong, but no one got hurt. In contrast, if we incorrectly predict that an individual will <em>not</em> suffer a shark attach, then this is a big problem which potentially involves grievous bodily injury, death, trauma, legal liability, etc. So, in designing our predictor, we might want to prioritizing avoiding the second kind of error, even if that leads us to make more of the first kind of error.</p>
<p>What <em>are</em> the types of error? For a binary (yes/no) outcome with a binary predictor, there are four possibilities:</p>
<div id="tbl-errors" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-tbl">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-errors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table 4.1: Types of correct classifications and errors in a binary classification problem.
</figcaption>
<div aria-describedby="tbl-errors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top">
<thead>
<tr class="header">
<th></th>
<th>Abbreviation</th>
<th style="text-align: center;">True Outcome</th>
<th style="text-align: center;">Predicted Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>True positive</td>
<td>TP</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>False negative</td>
<td>FN</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>False positive</td>
<td>FP</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>True negative</td>
<td>TN</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Given a vector of true outcomes <span class="math inline">\(\mathbf{y}\)</span> and a vector of predictions <span class="math inline">\(\hat{\mathbf{y}}\)</span>, we can calculate frequencies of each outcome. For example, here are the false positives associated with a given threshold value:</p>
<div id="eac8aae9" class="cell" data-execution_count="12">
<div class="sourceCode" id="cb15"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> s <span class="op">&gt;=</span> t </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># false positives: outcome == 0 and prediction == 1</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>((y_train <span class="op">==</span> <span class="dv">0</span>)<span class="op">*</span>(y_pred <span class="op">==</span> <span class="dv">1</span>)).<span class="bu">sum</span>()</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span></code></pre></div>
<div class="cell-output cell-output-display margin-caption" data-execution_count="137">
<pre><code>286</code></pre>
</div>
</div>
<p>In practice, it’s typically more convenient to compute all the error rates at once using the confusion matrix:</p>
<div id="b91417c6" class="cell" data-execution_count="13">
<div class="sourceCode" id="cb17"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>confusion_matrix(y_train, y_pred)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span></code></pre></div>
<div class="cell-output cell-output-display margin-caption" data-execution_count="138">
<pre><code>array([[18062,   286],
       [ 4319,   905]])</code></pre>
</div>
</div>
<p>The layout of the confusion matrix is:</p>
<pre><code>true negative,  false positive 
false negative, true positive</code></pre>
<p>It is common to normalize these counts into rates:</p>
<table class="caption-top">
<colgroup>
<col style="width: 43%" />
<col style="width: 10%" />
<col style="width: 43%" />
<col style="width: 2%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Abbreviation</th>
<th style="text-align: center;">Formula</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>True negative rate</td>
<td>TNR</td>
<td style="text-align: center;"><span class="math inline">\(\frac{\mathrm{FP}}{\mathrm{FP} + \mathrm{TN}}\)</span></td>
<td></td>
</tr>
<tr class="even">
<td>False positive rate</td>
<td>FPR</td>
<td style="text-align: center;"><span class="math inline">\(\frac{\mathrm{FP}}{\mathrm{FP} + \mathrm{TN}}\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td>False negative rate</td>
<td>FNR</td>
<td style="text-align: center;"><span class="math inline">\(\frac{\mathrm{FN}}{\mathrm{TP} + \mathrm{FN}}\)</span></td>
<td></td>
</tr>
<tr class="even">
<td>True positive rate</td>
<td>TPR</td>
<td style="text-align: center;"><span class="math inline">\(\frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}}\)</span></td>
<td></td>
</tr>
</tbody>
</table>
<p>Intuitively, the TPR measures the proportion of the time that the classifier predicts the correct (positive) label <em>when the true outcome was positive</em>. Similarly, the FPR measures the proportion of the time that the classifier predicts the incorrect (positive) label <em>when the true outcome was negative</em>. Because <span class="math inline">\(\mathrm{TPR} = 1 - \mathrm{FNR}\)</span> and <span class="math inline">\(\mathrm{FPR} = 1 - \mathrm{TNR}\)</span>, folks usually only bother remembering and using <span class="math inline">\(\mathrm{TPR}\)</span> and <span class="math inline">\(\mathrm{FNR}\)</span>.</p>
<p>Let’s compute the False Positive Rate (FPR) manually: <span class="column-margin margin-aside">Cases where <code>y_pred == 1</code> correspond to positive predictions, while cases where <code>y_train == 0</code> correspond to true negative outcomes.</span></p>
<div id="7971b919" class="cell" data-execution_count="14">
<div class="sourceCode" id="cb20"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># number of false positives / all true negatives</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>((y_pred <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (y_train <span class="op">==</span> <span class="dv">0</span>)).<span class="bu">sum</span>() <span class="op">/</span> (y_train <span class="op">==</span> <span class="dv">0</span>).<span class="bu">sum</span>()</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span></code></pre></div>
<div class="cell-output cell-output-display margin-caption" data-execution_count="139">
<pre><code>0.015587529976019185</code></pre>
</div>
</div>
<p>Rather than computing these by hand, Scikit-learn offers a handy argument to <code>confusion_matrix</code> for computing these automatically and simultaneously:</p>
<div id="40d37583" class="cell" data-execution_count="15">
<div class="sourceCode" id="cb22"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># top right corner agrees with manual computation. </span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>confusion_matrix(y_train, y_pred, normalize <span class="op">=</span> <span class="st">&quot;true&quot;</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co">#---</span></span></code></pre></div>
<div class="cell-output cell-output-display margin-caption" data-execution_count="140">
<pre><code>array([[0.984, 0.016],
       [0.827, 0.173]])</code></pre>
</div>
</div>
<section id="the-roc-curve" class="level3">
<h3>The ROC Curve</h3>
<p>The four error rates are mathematically related to each other: <span class="math inline">\(\mathrm{TPR} + \mathrm{FNR} = 1\)</span> and <span class="math inline">\(\mathrm{TNR} + \mathrm{FPR} = 1\)</span>. This means that there are really only two distinct numbers to keep track of: if we know the TPR and FPR, for example, then we can compute the FNR and TNR from them. It is common to explore the complete space of all possible TPRs and FPRs by varying the threshold <span class="math inline">\(t\)</span>. This defines a parametrized function, a curve in TPR-FPR space. This curve is the ROC curve <span class="column-margin margin-aside">ROC stands for “receiver operating characteristic,” a term that reflects the origin of the curve in detection of objects by radar.</span></p>
<p>To compute an ROC curve, we simply need to compute the TPR and FPR for many different values of the threshold <span class="math inline">\(t\)</span> and plot them.</p>
<div id="cd7d8f0c" class="cell" data-execution_count="16">
<div class="sourceCode" id="cb24"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize <span class="op">=</span> (<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>num_thresholds <span class="op">=</span> <span class="dv">101</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>FPR <span class="op">=</span> np.zeros(num_thresholds)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>TPR <span class="op">=</span> np.zeros(num_thresholds)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> np.linspace(s.<span class="bu">min</span>()<span class="op">-</span><span class="fl">0.1</span>, s.<span class="bu">max</span>()<span class="op">+</span><span class="fl">0.1</span>, num_thresholds)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>s    <span class="op">=</span> linear_score(X_train, w)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_thresholds):</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> T[i]</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    preds    <span class="op">=</span> s <span class="op">&gt;=</span> t</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    FPR[i]   <span class="op">=</span> ((preds <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (y_train <span class="op">==</span> <span class="dv">0</span>)).<span class="bu">sum</span>() <span class="op">/</span> (y_train <span class="op">==</span> <span class="dv">0</span>).<span class="bu">sum</span>()</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    TPR[i]   <span class="op">=</span> ((preds <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (y_train <span class="op">==</span> <span class="dv">1</span>)).<span class="bu">sum</span>() <span class="op">/</span> (y_train <span class="op">==</span> <span class="dv">1</span>).<span class="bu">sum</span>()</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>ax.plot(FPR, TPR, color <span class="op">=</span> <span class="st">&quot;black&quot;</span>)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>ax.plot([<span class="dv">0</span>,<span class="dv">1</span>], [<span class="dv">0</span>,<span class="dv">1</span>], linestyle<span class="op">=</span><span class="st">&quot;--&quot;</span>, color <span class="op">=</span> <span class="st">&quot;grey&quot;</span>)</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>ax.set_aspect(<span class="st">&#39;equal&#39;</span>)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>labs <span class="op">=</span> ax.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">&quot;False Positive Rate&quot;</span>, ylabel <span class="op">=</span> <span class="st">&quot;True Positive Rate&quot;</span>, title <span class="op">=</span> <span class="st">&quot;ROC Curve&quot;</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img src="04-decision-theory_files/figure-html/cell-17-output-1.png" class="margin-caption" width="355" height="368" /></p>
</figure>
</div>
</div>
</div>
<p>We can think of the ROC curve as a description of all the possible tradeoffs between the TPR and FPR that are achievable for a given score as we vary the threshold <span class="math inline">\(t\)</span>. For example, the curve tells us that if we are willing to tolerate a false positive rate of 0.40, then the best true positive rate we can achieve is approximately 0.77.</p>
<p>ROC curves are often used as a measure of the ability of a score function to classify data into two groups. Curves that bend farther towards the upper left corner of the plot are generally viewed as more effective classifiers, while curves which follow the dashed line of equality correspond to models that are no better than random chance. The area under the curve (AUC) is sometimes used as a single quantitative measure describing the classification quality.</p>
</section>
<section id="cost-of-errors-and-optimal-thresholding" class="level3">
<h3>Cost of Errors and Optimal Thresholding</h3>
<p>How do we choose the tradeoff that works best for us? To answer this kind of question, we need to reflect back on the <em>purpose</em> for which we are building a classifier. According to <a href="#tbl-errors" class="quarto-xref">Table <span class="quarto-unresolved-ref">tbl-errors</span></a>, there are two ways to be correct (true positive, true negative) and two ways to make an error (false positive, false negative). In order to choose an appropriate tradeoff, we need to think about the <em>benefit</em> of being right in relation to the <em>cost</em> of being wrong. We can define an <em>expected benefit from prediction</em> like this:</p>
<p><span id="eq-cost-benefit"><span class="math display">\[
\begin{aligned}
    \text{Benefit} =  &amp;\phantom{-}\text{TP}\times (\text{benefit of TP}) + \text{TN} \times (\text{benefit of TN}) \\  
    &amp; \color{white}{-}\text{FP} \times (\text{cost of FP})  - \text{FN}\times(\text{cost of FN})\;.
\end{aligned}
\tag{4.2}\]</span></span></p>
<p>To specify our estimated benefit, we must therefore specify the two costs and two benefits using information from our specific decision-making context.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-body-container">
<p>How would you suggest setting the two cost and two benefit terms in <a href="#eq-cost-benefit" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-cost-benefit</span></a> in the following prediction contexts?</p>
<ul>
<li>Shark attack prediction.</li>
<li>Prediction of whether or not an email is spam.</li>
<li>Prediction of whether or not a patient has a rare disease.</li>
<li>Prediction of whether an individual is likely to be arrested for a crime if released on parole.</li>
</ul>
</div>
</div>
</div>
<p>So far, we have framed the prediction problem of credit default from the bank’s perspective – the bank assesses customers and makes a decision. To continue in this vein, let’s consider how a bank might fill out each of the four terms above. In the lending business, a bank can <em>make</em> money when loans are fully repaid with interest, but <em>lose</em> money (usually much more) when an individual defaults on the loan. On the other hand, when the bank chooses not to make a loan at all (in response to a negative prediction), no credit is extended and there is no gain or loss. So, heuristically,</p>
<p>To keep the problem simple, suppose that the bank gains $1 every time they make a loan which is successfully paid back, and that the bank loses $2 every time they make a loan which ends in default. The first scenario happens when the bank makes a true positive identification, while the second case happens when the bank makes a false negative classification. <span class="column-margin margin-aside">Remember that the “positive” outcome in this data set is default.</span> For a given threshold, the expected gain for the bank when making a loan is then</p>
<p><span class="math display">\[
\begin{aligned}
    \mathbb{E}[\mathrm{gain}] = 1\times \text{TN} - 2\times \text{FN}\;.
\end{aligned}
\]</span></p>
<p>Let’s plot the expected gain as a function of the threshold:</p>
<div id="231c5d02" class="cell" data-execution_count="17">
<div class="sourceCode" id="cb25"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>TNR <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> FPR</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>FNR <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> TPR</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>cost_of_FN <span class="op">=</span> <span class="op">-</span><span class="fl">2.0</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>gain_of_TN <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>gain <span class="op">=</span>  gain_of_TN<span class="op">*</span>TNR  <span class="op">+</span> cost_of_FN<span class="op">*</span>FNR </span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>plt.plot(T, gain)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(ylim <span class="op">=</span> (<span class="op">-</span><span class="fl">0.2</span>, <span class="fl">0.2</span>), xlim <span class="op">=</span> (<span class="dv">0</span>, <span class="fl">0.5</span>))</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>labs <span class="op">=</span> plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="vs">r&quot;Threshold $t$&quot;</span>, ylabel <span class="op">=</span> <span class="st">&quot;Expected profit per loan&quot;</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img src="04-decision-theory_files/figure-html/cell-18-output-1.png" class="margin-caption" width="605" height="428" /></p>
</figure>
</div>
</div>
</div>
<p>For these costs, we observe that the bank can make a small expected profit (roughly 17 cents per loan) by using the given score function with threshold of roughly <span class="math inline">\(t \approx 0.21\)</span>. Note that this is very different from the value of the thresold <span class="math inline">\(t \approx 0.4\)</span> which maximized the unweighted accuracy of the predictor.</p>
<p>At this stage, we could go on to estimate the profit gained by using this predictor and threshold on the test data set instead of the training data set. The code below simply consolidates the many steps that we have walked through in these notes, applied to the test data.</p>
<div id="4480f5e7" class="cell" data-execution_count="18">
<div class="sourceCode" id="cb26"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> <span class="fl">0.21</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co"># compute the scores</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>s     <span class="op">=</span> linear_score(X_test, w)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> s <span class="op">&gt;=</span> t</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co"># compute error rates</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>FPR   <span class="op">=</span> ((preds <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (y_test <span class="op">==</span> <span class="dv">0</span>)).<span class="bu">sum</span>() <span class="op">/</span> (y_test <span class="op">==</span> <span class="dv">0</span>).<span class="bu">sum</span>()</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>TPR   <span class="op">=</span> ((preds <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (y_test <span class="op">==</span> <span class="dv">1</span>)).<span class="bu">sum</span>() <span class="op">/</span> (y_test <span class="op">==</span> <span class="dv">1</span>).<span class="bu">sum</span>()</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>TNR <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> FPR</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>FNR <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> TPR</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="co"># compute the expected gain</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>gain <span class="op">=</span> gain_of_TN<span class="op">*</span>TNR  <span class="op">+</span> cost_of_FN<span class="op">*</span>FNR </span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>gain</span></code></pre></div>
<div class="cell-output cell-output-display margin-caption" data-execution_count="143">
<pre><code>0.17641653321131712</code></pre>
</div>
</div>
<p>Our performance on the test data is very slightly worse than our performance on the training data, which is to be expected.</p>
</section>
</section>
<section id="recap" class="level2">
<h2>Recap</h2>
<p>In these notes, we studied a simple question: given a score <span class="math inline">\(s_i = \langle \mathbf{x}_i, \mathbf{w}\rangle\)</span>, how should we convert that score into a yes/no decision? We found that adjusting the threshold can have major consequences for the accuracy of the resulting classification algorithm, but also that pure accuracy may not be the most relevant metric to measure or optimize. We computed the ROC curve of the score, which is a visual indicator of the overall ability of the score function to balance the false positive rate against the true positive rate. Finally, we explored the possible tradeoffs between different kinds of errors by considering a simplified scenario in which different kinds of errors have different costs associated with them. We found that the threshold that optimizes expected gain under this setting can be very different from the threshold that optimizes unweighted accuracy.</p>
</section>
<section id="who-sets-the-cost-who-pays-the-cost" class="level2">
<h2>Who Sets The Cost? Who Pays the Cost?</h2>
<p>In our analysis above, we assumed a simple optimization objective: the bank is going to maximize its net profit. In formulating this objective, we made assumptions about the costs of different outcomes – <strong>to the bank</strong>. It’s important to note that the costs of errors to the bank may look very different from the costs of those errors to individuals. For example, if the bank’s prediction system recommends that an individual be denied a loan and the bank acts on this recommendation, then the bank pays no cost. On the other hand, the individual may experience major costs, depending on the purpose for which the loan was requested.</p>
<p>This data set includes a coarse description of the purpose of each loan:</p>
<div id="4cdafe12" class="cell" data-execution_count="19">
<div class="sourceCode" id="cb28"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>df_all.groupby(<span class="st">&quot;loan_intent&quot;</span>).size()</span></code></pre></div>
<div class="cell-output cell-output-display margin-caption" data-execution_count="144">
<pre><code>loan_intent
DEBTCONSOLIDATION    5212
EDUCATION            6453
HOMEIMPROVEMENT      3605
MEDICAL              6071
PERSONAL             5521
VENTURE              5719
dtype: int64</code></pre>
</div>
</div>
<p>What are the costs of being denied access to borrowed funds to pursue education? What about for medical care?</p>
<p>It is of fundamental importance to remember that machine learning systems are embedded in social context; that they are generally developed and implemented by people and organizations that occupy positions of power; and that the costs of these systems are often unequally shared by the people they impact. We will discuss these considerations in much greater detail soon.</p>
<div id="quarto-navigation-envelope" class="hidden">
<p><span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar-title">Machine Learning</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-navbar-title">Machine Learning</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-next"><span class="chapter-number">5</span>  <span class="chapter-title">Introduction to Algorithmic Disparity: COMPAS</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-prev"><span class="chapter-number">3</span>  <span class="chapter-title">Score-Based Classification</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/index.htmlWelcome">Welcome</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:quarto-sidebar-section-1">Introducing Machine Learning</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/01-data-and-models.html&lt;span-class=&#39;chapter-number&#39;&gt;1&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Data,-Patterns,-and-Models&lt;/span&gt;"><span class="chapter-number">1</span>  <span class="chapter-title">Data, Patterns, and Models</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/02-black-box-classification.html&lt;span-class=&#39;chapter-number&#39;&gt;2&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Classification-as-a-Black-Box&lt;/span&gt;"><span class="chapter-number">2</span>  <span class="chapter-title">Classification as a Black Box</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:quarto-sidebar-section-2">Fundamentals of Prediction</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/03-score-based-classification.html&lt;span-class=&#39;chapter-number&#39;&gt;3&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Score-Based-Classification&lt;/span&gt;"><span class="chapter-number">3</span>  <span class="chapter-title">Score-Based Classification</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/04-decision-theory.html&lt;span-class=&#39;chapter-number&#39;&gt;4&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Decision-Theory-in-Classification&lt;/span&gt;"><span class="chapter-number">4</span>  <span class="chapter-title">Decision Theory in Classification</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:quarto-sidebar-section-3">Discrimination, Disparity, Data</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/10-compas.html&lt;span-class=&#39;chapter-number&#39;&gt;5&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Introduction-to-Algorithmic-Disparity:-COMPAS&lt;/span&gt;"><span class="chapter-number">5</span>  <span class="chapter-title">Introduction to Algorithmic Disparity: COMPAS</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/12-statistical-fairness.html&lt;span-class=&#39;chapter-number&#39;&gt;6&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Statistical-Definitions-of-Fairness-in-Decision-Making&lt;/span&gt;"><span class="chapter-number">6</span>  <span class="chapter-title">Statistical Definitions of Fairness in Decision-Making</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:quarto-sidebar-section-4">Machine Learning Models</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/20-perceptron.html&lt;span-class=&#39;chapter-number&#39;&gt;7&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Introduction-to-Classification:-The-Perceptron&lt;/span&gt;"><span class="chapter-number">7</span>  <span class="chapter-title">Introduction to Classification: The Perceptron</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/22-convex-erm.html&lt;span-class=&#39;chapter-number&#39;&gt;8&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Convex-Empirical-Risk-Minimization&lt;/span&gt;"><span class="chapter-number">8</span>  <span class="chapter-title">Convex Empirical Risk Minimization</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/23-gradient-descent.html&lt;span-class=&#39;chapter-number&#39;&gt;9&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Optimization-with-Gradient-Descent&lt;/span&gt;"><span class="chapter-number">9</span>  <span class="chapter-title">Optimization with Gradient Descent</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/30-features-regularization.html&lt;span-class=&#39;chapter-number&#39;&gt;10&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Feature-Maps,-Regularization,-and-Generalization&lt;/span&gt;"><span class="chapter-number">10</span>  <span class="chapter-title">Feature Maps, Regularization, and Generalization</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/40-linear-regression.html&lt;span-class=&#39;chapter-number&#39;&gt;11&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Linear-Regression&lt;/span&gt;"><span class="chapter-number">11</span>  <span class="chapter-title">Linear Regression</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/50-kernel-methods.html&lt;span-class=&#39;chapter-number&#39;&gt;12&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Kernel-Methods&lt;/span&gt;"><span class="chapter-number">12</span>  <span class="chapter-title">Kernel Methods</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/51-vectorization.html&lt;span-class=&#39;chapter-number&#39;&gt;13&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Vectorization-and-Feature-Engineering&lt;/span&gt;"><span class="chapter-number">13</span>  <span class="chapter-title">Vectorization and Feature Engineering</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:quarto-sidebar-section-5">Deep Learning</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/60-intro-deep.html&lt;span-class=&#39;chapter-number&#39;&gt;14&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;The-Problem-of-Features-and-Deep-Learning&lt;/span&gt;"><span class="chapter-number">14</span>  <span class="chapter-title">The Problem of Features and Deep Learning</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/61-modern-optimization.html&lt;span-class=&#39;chapter-number&#39;&gt;15&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Contemporary-Optimization&lt;/span&gt;"><span class="chapter-number">15</span>  <span class="chapter-title">Contemporary Optimization</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/70-image-classification.html&lt;span-class=&#39;chapter-number&#39;&gt;16&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Deep-Image-Classification&lt;/span&gt;"><span class="chapter-number">16</span>  <span class="chapter-title">Deep Image Classification</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/72-text-classification.html&lt;span-class=&#39;chapter-number&#39;&gt;17&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Text-Classification-and-Word-Embedding&lt;/span&gt;"><span class="chapter-number">17</span>  <span class="chapter-title">Text Classification and Word Embedding</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:quarto-sidebar-section-6">Unsupervised Learning</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/80-unsupervised-autoencoders.html&lt;span-class=&#39;chapter-number&#39;&gt;18&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Unsupervised-Learning-and-Autoencoders&lt;/span&gt;"><span class="chapter-number">18</span>  <span class="chapter-title">Unsupervised Learning and Autoencoders</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/source/81-neural-autoencoders.html&lt;span-class=&#39;chapter-number&#39;&gt;19&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Neural-Autoencoders-and-Dimensionality-Reduction&lt;/span&gt;"><span class="chapter-number">19</span>  <span class="chapter-title">Neural Autoencoders and Dimensionality Reduction</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-breadcrumbs-Fundamentals-of-Prediction">Fundamentals of Prediction</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-breadcrumbs-&lt;span-class=&#39;chapter-number&#39;&gt;4&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Decision-Theory-in-Classification&lt;/span&gt;"><span class="chapter-number">4</span>  <span class="chapter-title">Decision Theory in Classification</span></span></p>
<div class="hidden quarto-markdown-envelope-contents" data-render-id="body-footer">
<div class="body-footer-item">
<p><br> <br> <span style="color:grey;">© Phil Chodrow, 2025</span></p>
</div>
</div>
</div>
<div id="quarto-meta-markdown" class="hidden">
<p><span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-metatitle"><span class="chapter-number">4</span>  <span class="chapter-title">Decision Theory in Classification</span> – Machine Learning</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-twittercardtitle"><span class="chapter-number">4</span>  <span class="chapter-title">Decision Theory in Classification</span> – Machine Learning</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-ogcardtitle"><span class="chapter-number">4</span>  <span class="chapter-title">Decision Theory in Classification</span> – Machine Learning</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-metasitename">Machine Learning</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-twittercarddesc"></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-ogcardddesc"></span></p>
</div>
</section>

</main> <!-- /main -->
<script id = "quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a  href="/source/03-score-based-classification.html" class="pagination-link" aria-label="Score-Based Classification">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class='chapter-number'>3</span>  <span class='chapter-title'>Score-Based Classification</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a  href="/source/10-compas.html" class="pagination-link" aria-label="Introduction to Algorithmic Disparity: COMPAS">
        <span class="nav-page-text"><span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction to Algorithmic Disparity: COMPAS</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->

</body>

</html>
