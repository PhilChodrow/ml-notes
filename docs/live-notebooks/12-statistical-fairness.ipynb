{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Definitions of Fairness in Decision-Making\n",
    "\n",
    "In these notes, we'll review three fundamental definitions of fairness for decision-making systems. While texts like @barocasFairnessMachineLearning2023 couch their definitions in the language of probability, our focus in these notes will be to relate the formal mathematical language to operational computations on data sets in Python. In doing so, we'll review some computational techniques via `pandas`, `numpy`, and `seaborn` from last time. After reviewing these definitions, we'll review a simple, famous result about the ability of decision systems to satisfy multiple definitions. \n",
    "\n",
    "For this study, we'll return to the COMPAS data that we studied [last time](../chapters/10-compas.qmd). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.set_printoptions(precision = 3)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/compas/compas.csv\"\n",
    "compas = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For this discussion, we again only need to consider a subset of the columns, and we'll focus exclusively on white (Caucasian) and Black (African-American) defendants: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"sex\", \"race\", \"decile_score\", \"two_year_recid\"]\n",
    "compas = compas[cols]\n",
    "\n",
    "# using Angwin's definition\n",
    "compas[\"predicted_high_risk\"] = 1*(compas[\"decile_score\"] > 4)\n",
    "\n",
    "\n",
    "is_white = compas[\"race\"] == \"Caucasian\"\n",
    "is_black = compas[\"race\"] == \"African-American\"\n",
    "\n",
    "compas = compas[is_white | is_black]\n",
    "compas = compas.copy()\n",
    "\n",
    "# excerpt of the data\n",
    "\n",
    "compas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Three Statistical Definitions of Fairness\n",
    "\n",
    "Last time, we introduced the idea that fairness in decision-making could be defined formally, and models could be audited to determine the extent to which those models conformed to a given definition. In this section, we'll discuss some of the definitions in Chapter 3 of @barocasFairnessMachineLearning2023 and implement Python functions to measure the extent to which the COMPAS risk score conforms to those definitions. \n",
    "\n",
    "To line ourselves up with the notation of @barocasFairnessMachineLearning2023, let's define the following random variables: Let $A$ be a random variable that describes the group membership of an individual. Let $Y$ be the outcome we want to predict. Let $R$ be the value of our risk score. Let $\\hat{Y}$ be our model's prediction about whether $Y$ occurs. \n",
    "\n",
    "In the case of COMPAS: \n",
    "\n",
    "- $A$ is the race of the individual, with possible values $A = a$ and $A = b$. \n",
    "- $Y = 1$ if the individual was arrested within two years after release, and $Y = 0$ if not. \n",
    "- $R$ is the decile risk score. \n",
    "- $\\hat{Y} = 1$ if $R \\geq 4$ and $\\hat{Y} = 0$ otherwise. \n",
    "\n",
    "### Statistical Independence\n",
    "\n",
    "Here's our first concept of fairness: **independence**. For our present purposes, we focus on the definition of independence for binary classifiers as given by @barocasFairnessMachineLearning2023. \n",
    "\n",
    "::: {.callout-note}\n",
    "\n",
    "::: {#def-independence}\n",
    "\n",
    "## Statistical Independence For Binary Classifiers \n",
    "\n",
    "[Recall that $\\mathbb{P}(Y = 1|A = a)$ is the probability that $Y = 1$ *given* that $A=a$. It can be computed using the formula $\\mathbb{P}(Y = 1|A = a) = \\frac{\\mathbb{P}(Y = 1, A = a)}{\\mathbb{P}(A = a)}$.]{.aside}\n",
    "The model predictions $\\hat{Y}$ satisfy *statistical independence* if $\\mathbb{P}(\\hat{Y} = 1 | A = a) = {P}(\\hat{Y} = 1 | A = b)$. \n",
    "\n",
    ":::\n",
    "\n",
    ":::\n",
    "\n",
    "Colloquially, @def-independence says that the probability of a positive prediction $\\hat{Y} = 1$ does not depend on the group membership $A$. In the COMPAS data, independence would require that the probability of the model predicting that an individual will be arrested within two years be the same for Black and white defendants. \n",
    "\n",
    "Let's write a Python function to empirically check independence that will accept a data frame `df` and three additional arguments: \n",
    "\n",
    "[For independence, we don't actually need the `target` column, but this approach will let us keep a consistent API for our more complicated implementations below.]{.aside}\n",
    "\n",
    "- `group_col`, the name of the column describing group memberships. \n",
    "- `target`, the name of the column holding the binary outcomes. \n",
    "- `pred`, the name of the column holding the predicted binary outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's run our function to check for independence: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_independence(compas, \"race\", \"two_year_recid\", \"predicted_high_risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The `mean` column gives the proportion of the time in which the predictor $\\hat{Y}$ had value equal to 1, for each of the two groups. This is an empirical estimate of the probability $\\mathbb{P}(\\hat{Y} = 1 | A = a)$. We can see that the two proportions are substantially different between groups, strongly suggesting that this model violates the independence criterion. [Formally, statistical tests beyond the scope of this course would be needed to reject the hypothesis that the two proportions are different. In this case, you can take my word for it that the relevant test provides strong support for rejecting the null.]{.aside} \n",
    "\n",
    "As discussed in @barocasFairnessMachineLearning2023, independence is a very strong expression of the idea that predictions, and therefore automated decisions, should be the same in aggregate across all groups present in the data. This idea sometimes accompanies another idea, that all groups are equally worthy, meritorious, or deserving of a given decision outcome. \n",
    "\n",
    "### Error-Rate Balance\n",
    "\n",
    "[This definition can be generalized from binary classifiers to score functions via the concept of *separation*, which is discussed in @barocasFairnessMachineLearning2023.]{.aside}\n",
    "The primary finding of @angwin2022machine was, famously, that the COMPAS algorithm makes very different kinds of errors on Black and white defendants. \n",
    "\n",
    "\n",
    "::: {.callout-note}\n",
    "\n",
    "::: {#def-error-rate-balance}\n",
    "\n",
    "\n",
    "## Error Rate Balance for Binary Classifiers\n",
    "\n",
    "The model predictions $\\hat{Y}$ satisfy *error-rate balance* if the following conditions both hold: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbb{P}(\\hat{Y} = 1 | Y = 1, A = a) &= \\mathbb{P}(\\hat{Y} =1  | Y = 1, A = b) & \\text{(balanced true positives)} \\\\ \n",
    "    \\mathbb{P}(\\hat{Y} = 1 | Y = 0, A = a) &= \\mathbb{P}(\\hat{Y} =1  | Y = 0, A = b)\\;. & \\text{(balanced false positives)} \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    ":::\n",
    "\n",
    ":::\n",
    "\n",
    "Error rate balance requires that the true positive rate and false positive rates be equal on the two groups. Given some data in which we have $\\mathrm{TP}$ instances of true positives, $\\mathrm{FP}$ instances of false positives, $\\mathrm{TN}$ instances of true negatives, and $\\mathrm{FN}$ instances of false negatives, we can estimate the TPR and FPR via the formulas \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathrm{TPR} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}} \\\\  \n",
    "    \\mathrm{FPR} &= \\frac{\\mathrm{FP}}{\\mathrm{FP} + \\mathrm{TN}}\\;. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Let's write another function with the same API to give a summary of error rates between two groups using these formulas. As we know, it's pretty convenient to do this with confusion matrices. It's not much more difficult to do it \"by hand\" using vectorized Pandas computations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can use this function to do an empirical test for error rate balance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[As before, before concluding that the COMPAS algorithm violates error rate balance as in @def-error-rate-balance, it is technically necessary to perform a statistical test to reject the null hypothesis that the true population error rates are the same.]{.aside}\n",
    "The false positive rates are in the rows in which `two_year_recid == 0`, and the true positive rates are in the rows in which `two_year_recid == 1`. \n",
    "\n",
    "### Sufficiency \n",
    "\n",
    "Finally, as we mentioned last time, the analysis of @angwin2022machine received heavy pushback from @flores2016false and others, who argued that error rate balance wasn't really the right thing to measure. Instead, we should check *sufficiency*, which we'll define here for binary classifiers: \n",
    "\n",
    "::: {.callout-note}\n",
    "\n",
    "::: {#def-sufficiency}\n",
    "\n",
    "## Sufficiency\n",
    "\n",
    "Model predictions $\\hat{Y}$ satisfy *sufficiency* if the following two conditions hold: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbb{P}(Y = 1 | \\hat{Y} = 1, A = a) &= \\mathbb{P}(Y = 1 | \\hat{Y} = 1, A = b) \\\\ \n",
    "    \\mathbb{P}(Y = 0 | \\hat{Y} = 0, A = a) &= \\mathbb{P}(Y = 0 | \\hat{Y} = 0, A = b) \\;. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "::: \n",
    ":::\n",
    "\n",
    "The quantity $\\mathbb{P}(Y = 1 | \\hat{Y} = 1, A = a)$ is sometimes called the *positive predictive value* (PPV) of $\\hat{Y}$ for group $a$. You can think of it as the \"*value*\" of a *positive prediction*: given that the prediction is positive ($\\hat{Y} = 1$) for a member of group $a$, how likely is it that the prediction is accurate? Similarly, $\\mathbb{P}(Y = 0 | \\hat{Y} = 0, A = a)$ is sometimes called the *negative predictive value* (NPV) of $\\hat{Y}$ for group $a$. So, the sufficiency criterion demands that the positive and negative predictive values be equal across groups. \n",
    "\n",
    "Given some data in which we have $\\mathrm{TP}$ instances of true positives, $\\mathrm{FP}$ instances of false positives, $\\mathrm{TN}$ instances of true negatives, and $\\mathrm{FN}$ instances of false negatives, we can estimate the PPV and NPV via the formulas \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathrm{PPV} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}} \\\\  \n",
    "    \\mathrm{NPV} &= \\frac{\\mathrm{TN}}{\\mathrm{TN} + \\mathrm{FN}}\\;. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Let's write a function to check for sufficiency in the COMPAS predictions. This function will compute the positive and negative predictive values by group: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sufficiency(compas, \"race\", \"two_year_recid\", \"predicted_high_risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The negative predictive values are in the rows in which `predicted_high_risk == 0` and the positive predictive values are in the rows in which `predicted_high_risk == 1`. We observe that the negative predictive value is slightly higher for white defendants, while the positive predictive value is slightly higher for Black defendants. These differences, however, are much lower than the error rate disparity noted above. \n",
    "\n",
    "## Can We Have It All? \n",
    "\n",
    "Ok, well COMPAS isn't an ideal algorithm by any means. But couldn't we just define some more conceptions of fairness, pick the ones that we wanted to use, and then design an algorithm that satisfied all of them? \n",
    "\n",
    "Sadly, no: we can't even have error rate balance and sufficiency simultaneously. \n",
    "\n",
    "::: {.callout-tip} \n",
    "\n",
    "::: {#thm-incompatibility}\n",
    "\n",
    "## Incompatibility of Error Rate Balance and Sufficiency [@chouldechovaFairPredictionDisparate2017a]\n",
    "\n",
    "If the true rates $p_a$ and $p_b$ of positive outcomes in the groups $a$ and $b$ are not equal ($p_a \\neq p_b$), then there does not exist a model that produces predictions which satisfy both error rate balance and sufficiency. \n",
    "\n",
    ":::\n",
    ":::\n",
    "\n",
    "::: {.proof}\n",
    "\n",
    "Our big-picture approach is proof by contrapositive. We'll show that if there were a model that satisfied error rate balance and sufficiency, then $p_a = p_b$. \n",
    "\n",
    "Let's briefly forget about group labels -- we'll reintroduce them in a moment. \n",
    "\n",
    "First, the prevalence of positive outcomes is the fraction of positive outcomes. There are $\\mathrm{TP} + \\mathrm{FN}$ total positive outcomes, and $\\mathrm{TP} + \\mathrm{FP} + \\mathrm{TN} + \\mathrm{FN}$ outcomes overal, so we can write the prevalence as \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    p = \\frac{\\mathrm{TP} + \\mathrm{FN}}{\\mathrm{TP} + \\mathrm{FP} + \\mathrm{TN} + \\mathrm{FN}};. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "From above, the true and false positive rates are: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathrm{TPR} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}} \\\\ \n",
    "    \\mathrm{FPR} &= \\frac{\\mathrm{FP}}{\\mathrm{FP} + \\mathrm{TN}}\\;.  \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The PPV is: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathrm{PPV} = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}}\\;. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Ok, now it's time to do some algebra. Let's start with the $\\mathrm{TPR}$ and see if we can find an equation that relates it to the $\\mathrm{FPR}$. First, we'll multiply by $\\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}}$. If we do this and insert the definitions of these quantities, we'll get \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathrm{TPR} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}} \\frac{\\mathrm{FP}}{\\mathrm{TP} + \\mathrm{FP}} \\frac{\\mathrm{TP} + \\mathrm{FP}}{\\mathrm{TP}} \\\\ \n",
    "    &= \\frac{\\mathrm{FP}}{\\mathrm{TP} + \\mathrm{FN}}\\;. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Let's now also multiply by a factor of $\\frac{p}{1-p}$: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathrm{TPR} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}}\\frac{p}{1-p} &= \\frac{\\mathrm{FP}}{\\mathrm{TP} + \\mathrm{FN}}\\frac{p}{1-p} \\\\ \n",
    "    &= \\frac{\\mathrm{FP}}{\\mathrm{TP} + \\mathrm{FN}} \\frac{\\mathrm{TP} + \\mathrm{FN}}{\\mathrm{TP} + \\mathrm{FP} + \\mathrm{TN} + \\mathrm{FN}} \\frac{\\mathrm{TP} + \\mathrm{FP} + \\mathrm{TN} + \\mathrm{FN}}{\\mathrm{FP} + \\mathrm{TN}} \\\\ \n",
    "    &= \\frac{\\mathrm{FP}}{\\mathrm{FP} + \\mathrm{TN}} \\\\ \n",
    "    &= \\mathrm{FPR}\\;. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "So, with some algebra, we have proven an equation for any classifier: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathrm{TPR} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}}\\frac{p}{1-p} = \\mathrm{FPR}\\;. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "It's convenient to rearrange this equation slightly: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\frac{\\mathrm{TPR}}{\\mathrm{FPR}} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}} = \\frac{1-p}{p}\\;. \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "or \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    p = \\left(1 + \\frac{\\mathrm{TPR}}{\\mathrm{FPR}} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}}\\right)^{-1}\\;. \n",
    "\\end{aligned}\n",
    "$${#eq-rearranged-for-p}\n",
    "\n",
    "Now suppose that I want to enforce error rate balance and sufficiency for two groups $a$ and $b$, where $p_a \\neq p_b$.  So, from error rate balance I am going to require that $\\mathrm{TPR}_a = \\mathrm{TPR}_b$, $\\mathrm{FPR}_a = \\mathrm{FPR}_b$, and from sufficiency I am going to enforce that $\\mathrm{PPV}_a = \\mathrm{PPV}_b$. Now, however, we have a problem: by @eq-rearranged-for-p, it must also be the case that $p_a = p_b$. This contradicts our assumption from the theorem. We cannot mathematically satisfy both error rate balance and sufficiency. This completes the proof. \n",
    "\n",
    ":::\n",
    "\n",
    "::: {.callout-note}\n",
    "\n",
    "## Discussion\n",
    "\n",
    "Do you feel that it is more important for a recidivism prediction algorithm like COMPAS to satisfy error rate balance or sufficiency? Why?\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "## Fairness, Context, and Legitimacy\n",
    "\n",
    "The proof above shows that, when the prevalences of positive outcomes differ between groups, we have no hope of being able to have both balanced error rates and sufficiency. In Chapter 3, @barocasFairnessMachineLearning2023 give a few other examples of fairness definitions, as well as proofs that some of these definitions are incompatible with each other. We can't just have it all -- we have to choose. \n",
    "\n",
    "The quantitative story of fairness in automated decision-making is not cut-and-dried -- we need to make choices, which may be subject to politics. Let's close this discussion with three increasingly difficult questions:\n",
    "\n",
    "1. What is the right definition of fairness by which to judge the operation of a decision-making algorithm? \n",
    "2. Is \"fairness\" even the right rubric for assessing the impact of a given algorithm? \n",
    "3. Is it legitimate to use automated decision-making *at all* for a given application context? \n",
    "\n",
    "We'll consider each of these questions soon. \n",
    "\n",
    "\n",
    "## References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
