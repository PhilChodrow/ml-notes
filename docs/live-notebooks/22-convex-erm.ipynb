{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "f0f78fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convex Empirical Risk Minimization\n",
    " \n",
    "[Last time](20-perceptron.ipynb), we studied the binary classification problem. In this problem, we assume that we have a *feature matrix* $\\mathbf{X} \\in \\mathbb{R}^{n\\times p}$. Each row of this feature matrix gives the predictor data (features) for each of $n$ total observations: \n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\left[\\begin{matrix} & - & \\mathbf{x}_1 & - \\\\ \n",
    "& - & \\mathbf{x}_2 & - \\\\ \n",
    "& \\vdots & \\vdots & \\vdots \\\\ \n",
    "& - & \\mathbf{x}_{n} & - \\end{matrix}\\right] \n",
    "$$\n",
    "\n",
    "We also have a *target vector* $\\mathbf{y} \\in \\{0,1\\}^n$. [For convenience, we will continue to assume that the final column of $\\mathbf{X}$ is a column of 1s; i.e. $x_{ip} = 1$ for all $i = 1,\\ldots,n$.]{.aside} Here's an example of how our training data might look: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig-scatter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: '300 data points in the 2d plane, each of which has one of two labels.'\n",
    "#| fig-cap-location: margin\n",
    "#| label: fig-scatter\n",
    "#| code-fold: true \n",
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "def classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n",
    "    \n",
    "    y = torch.arange(n_points) >= int(n_points/2)\n",
    "    y = 1.0*y\n",
    "    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n",
    "    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = classification_data(n_points = 300, noise = 0.2)\n",
    "\n",
    "def plot_classification_data(X, y, ax):\n",
    "    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n",
    "    targets = [0, 1]\n",
    "    markers = [\"o\" , \",\"]\n",
    "    for i in range(2):\n",
    "        ix = y == targets[i]\n",
    "        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -1, vmax = 2, alpha = 0.8, marker = markers[i])\n",
    "    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "X, y = classification_data()\n",
    "plot_classification_data(X, y, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "83b0df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "We continue to study the *linear* classification problem. We will find a vector of *weights* $\\mathbf{w}$ with the property that the hyperplane defined by the equation \n",
    "\n",
    "$$\n",
    "\\langle \\mathbf{w}, \\mathbf{x} \\rangle = 0\n",
    "$$\n",
    "\n",
    "approximately separates the two classes. \n",
    "\n",
    "## Modeling Choices\n",
    "\n",
    "Once we have chosen linear models as our tool, we can specify a model for the binary classification task by making two additional choices: \n",
    "\n",
    "1. **Loss**: How will we measure the success of the model in distinguishing the two classes?\n",
    "2. **Optimizer**: What algorithm will we use in order to minimize the loss? \n",
    "\n",
    "What choices did we make in the context of the perceptron?\n",
    "\n",
    "The **loss** function was the misclassification rate. If we let $s_i = \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle$, then we can write the loss like this:  [Here, the term $2y_i - 1$ transforms a $y_i$ with values in $\\{0,1\\}$ into one with values in $\\{-1,1\\}$.]{.aside}\n",
    "\n",
    "$$\n",
    "L(\\mathbf{w}) = \\frac{1}{n}\\sum_{i = 1}^n \\mathbb{1}[s_i (2y_i-1) < 0]\n",
    "$$\n",
    "\n",
    "The **optimizer** we used to minimize the loss was the perceptron update, in which we picked a random point $i$ and then performed the update\n",
    "\n",
    "[If $i$ is correctly classified (i.e. if $s_i(2 y_i - 1) > 0$), then the second term zeros out and nothing happens.]{.aside}\n",
    "$$\n",
    "\\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} + \\mathbb{1}[s_i (2y_i-1) < 0]y_i \\mathbf{x}_i\n",
    "$$\n",
    "\n",
    "However, as we saw, this doesn't actually work that well. There are two problems: \n",
    "\n",
    "1. Our problem with the **optimizer** was that this update won't actually converge if the data is not linearly separable. Maybe we could choose a better optimizer that would converge? \n",
    "2. Unfortunately not -- as we saw last time, the very problem of minimizing $L(\\mathbf{w})$ is NP-hard. This is a problem with the **loss function itself**. \n",
    "\n",
    "So, how could we choose a *better loss function* that would allow us to create efficient algorithms? \n",
    "\n",
    "## Convex Functions\n",
    "\n",
    "Let's start by visualizing a single term of the perceptron loss function. We'll view this as a function of the score $s$ and the true target value $y$: \n",
    "\n",
    "$$\n",
    "\\ell(s, y) = \\mathbb{1}[s (2y-1) < 0]\\;. \n",
    "$$\n",
    "\n",
    "We'll call this the *0-1 loss function*. Here's a plot of this function for each of the two possible values of $y$: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c2766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a2fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# or \n",
    "# hinge_loss = lambda s, y: 1*(s*(2*y-1) < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6f4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: 'The 0-1 loss function.'\n",
    "#| fig-cap-location: margin\n",
    "#| label: fig-0-1-loss\n",
    "#| code-fold: true\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "# plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "\n",
    "def plot_loss(loss_fun, show_line = False):\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        fig, axarr = plt.subplots(1, 2, figsize = (6, 3)) \n",
    "        s = torch.linspace(-1, 1, 10001)\n",
    "\n",
    "        for j in range(2):\n",
    "            y = [0, 1][j]\n",
    "            axarr[j].set_title(f\"y = {y}\")\n",
    "            axarr[j].set(xlabel = r\"$s$\", \n",
    "                        ylabel = r\"$\\ell(s, y)$\")\n",
    "            \n",
    "            ix1 = s < 0\n",
    "            axarr[j].plot(s[ix1], loss_fun(s[ix1], y), color = \"black\")\n",
    "            ix2 = s > 0\n",
    "            axarr[j].plot(s[ix2], loss_fun(s[ix2], y), color = \"black\")\n",
    "\n",
    "            if show_line: \n",
    "                s1 = torch.tensor([-0.7])\n",
    "                s2 = torch.tensor([0.9])\n",
    "\n",
    "                axarr[j].plot([s1, s2], [loss_fun(s1, y), loss_fun(s2, y)], color = \"darkgrey\", linestyle = \"--\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        return fig, axarr\n",
    "\n",
    "fig, axarr = plot_loss(loss_fun = zero_one_loss, show_line = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "3051d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprsingly, the problem with this loss function $\\ell$ is that we can \"draw lines under the function.\" What this means is that we can pick two points on the graph of the function, connect them with a line, and find that the line lies *under* the graph of the function in some regions: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f546f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: 'The 0-1 loss function with a line demonstrating that this function is nonconvex.'\n",
    "#| fig-cap-location: margin\n",
    "#| label: fig-0-1-loss-nonconvex\n",
    "#| code-fold: true\n",
    "\n",
    "fig, axarr = plot_loss(loss_fun = zero_one_loss, show_line = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "8ab5fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprisingly, this specific geometric property is what's blocking us from achieving performant searchability for the problem of finding $\\mathbf{w}$.  \n",
    "\n",
    "## Convex Loss Functions\n",
    "\n",
    "In order to develop convex loss functions, we need to define two concepts: \n",
    "\n",
    "::: {.callout-note}\n",
    "::: {#def-convex-set} \n",
    "\n",
    "A set $S \\subseteq \\mathbb{R}^n$ is *convex* if, for any two points $\\mathbf{z}_1, \\mathbf{z}_2 \\in S$ and for any $\\lambda \\in [0,1]$, the point $\\mathbf{z} = \\lambda \\mathbf{z}_1 + (1-\\lambda) \\mathbf{z}_2$ is also an element of $S$. \n",
    "\n",
    "::: \n",
    ":::\n",
    "\n",
    "We also need to define convex *functions*: \n",
    "\n",
    "\n",
    "::: {.callout-note}\n",
    "::: {#def-convex-function} \n",
    "\n",
    "## Convex Functions\n",
    "\n",
    "Let $S \\subseteq \\mathbb{R}^n$ be convex. A function $f:S \\rightarrow \\mathbb{R}$ is *convex* if, for any $\\lambda \\in \\mathbb{R}$ and any two points $\\mathbf{z}_1, \\mathbf{z}_2 \\in S$, we have \n",
    "\n",
    "$$\n",
    "f(\\lambda \\mathbf{z}_1 + (1-\\lambda)\\mathbf{z}_2) \\leq \\lambda f( \\mathbf{z}_1 ) + (1-\\lambda)f(\\mathbf{z}_2)\\;.\n",
    "$$\n",
    "\n",
    "The function $f$ is *strictly convex* if the inequality is strict: for all $\\lambda$, $\\mathbf{z}_1$, and $\\mathbf{z}_2$, \n",
    "\n",
    "$$\n",
    "f(\\lambda \\mathbf{z}_1 + (1-\\lambda)\\mathbf{z}_2) < \\lambda f( \\mathbf{z}_1 ) + (1-\\lambda)f(\\mathbf{z}_2)\\;.\n",
    "$$\n",
    "\n",
    ":::\n",
    ":::\n",
    "\n",
    "Roughly, a convex function is \"bowl-shaped,\" in the sense that any line connecting two points on its graph must lie above the graph.  The most familiar example of a convex function is our good friend the convex parabola: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: 'The convex parabola $f(x) = x^2$'\n",
    "#| fig-cap-location: margin\n",
    "#| label: fig-parabola\n",
    "#| code-fold: true\n",
    "\n",
    "x = torch.linspace(-1, 1, 10001)\n",
    "y = x**2\n",
    "\n",
    "plt.plot(x, y, color = \"black\")\n",
    "labs = plt.gca().set(xlabel = r\"$x$\", ylabel = r\"$f(x)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "d966a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Note that any straight line connecting two points on this graph always stays above the graph of the parabola. As we saw above, the 0-1 loss function $\\ell(s, y) = \\mathbb{1}[s(2y-1)<0]$ does not have this property. \n",
    "\n",
    "We can also define convex functions to replace the nonconvex 0-1 loss function from earlier. Here's an example, which is usually called the *hinge loss*, which is defined by the formula \n",
    "\n",
    "$$\n",
    "\\ell(s, y) = y \\max \\{0, s\\} + (1 - y) \\max\\{0, -s\\}\\;.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6716f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: 'The hinge loss function.'\n",
    "#| fig-cap-location: margin\n",
    "#| label: fig-hinge-loss\n",
    "#| code-fold: true\n",
    "\n",
    "fig, axarr = plot_loss(loss_fun = hinge_loss, show_line = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "bf20699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "The hinge loss is not strictly convex and is not even everywhere differentiable! Despite this, the fact that it is convex has made it a modern workhorse of machine learning. The support vector machine (SVM) operates by minimizing the hinge loss. The \"Rectified Linear Unit\" (ReLU) is a mainstay of modern deep learning--and is just another name for the hinge loss. \n",
    "\n",
    "An even handier loss function for our purposes is the sigmoid binary cross entropy, which is defined by the formula \n",
    "[In this formula, $\\sigma(s) = \\frac{1}{1 + e^{-s}}$ is the logistic sigmoid function.]{.aside}\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ell(s, y) &=  -y \\log \\sigma(s) - (1-y)\\log (1-\\sigma(s))\\;,\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# or \n",
    "# sig = lambda s: 1 / (1 + torch.exp(-s))\n",
    "# binary_cross_entropy = lambda s, y: -(y * sig(s).log() + (1 - y)*(1-sig(s)).log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3265e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: 'The binary cross-entropy loss function.'\n",
    "#| fig-cap-location: margin\n",
    "#| label: fig-cross-entropy-loss\n",
    "#| code-fold: true\n",
    "\n",
    "sig = lambda s: 1 / (1 + torch.exp(-s))\n",
    "binary_cross_entropy = lambda s, y: -(y * sig(s).log() + (1 - y)*(1-sig(s)).log())\n",
    "fig, axarr = plot_loss(loss_fun = binary_cross_entropy, show_line = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "1fb5f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "This function is also convex, and has the considerable benefit of being everywhere differentiable. \n",
    "\n",
    "We intentionally formulated our definition of convexity for functions of many variables. Here is a convex function $f:\\mathbb{R}^2 \\rightarrow \\mathbb{R}$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d52a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: 'A convex quadratic function of two variables.'\n",
    "#| fig-cap-location: margin\n",
    "#| label: fig-quadratic-3d\n",
    "#| code-fold: true\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "x = torch.linspace(-1, 1, 1001)[:, None]\n",
    "y = torch.linspace(-1, 1, 1001)[None, :]\n",
    "\n",
    "z = x**2 + y**2\n",
    "\n",
    "ax.plot_surface(x, y, z, cmap=\"inferno_r\",\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "labs = ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "c8ea6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "You could imagine trying to draw a straight line between two points on the graph of this function -- the line would always be above the graph. When thinking about convexity in many variables, it is often sufficient to imagine a bowl-shaped function like this one. \n",
    "\n",
    "\n",
    "## Convex Empirical Risk Minimization\n",
    "\n",
    "We are now ready to define the primary framework in which we will conduct supervised machine learning: convex empirical risk minimization. \n",
    "\n",
    "::: {.callout-note}\n",
    "::: {#def-empirical-risk}\n",
    "\n",
    "## Empirical Risk Minimization\n",
    "\n",
    "Given a loss function $\\ell:\\mathbb{R}\\times \\{0,1\\} \\rightarrow \\mathbb{R}$, a feature matrix $\\mathbb{X} \\in \\mathbb{R}^{n\\times p}$, a target vector $\\mathbf{y}$, and a parameter vector $\\mathbf{w} \\in \\mathbb{R}^p$, the *empirical risk of $\\mathbf{w}$* is \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\mathbf{w}) = \\frac{1}{n}\\sum_{i = 1}^n \\ell(s_i, y_i), \\quad&\\text{where }s_i = \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle\\;.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The *empirical risk minimization problem* is to find the value of $\\mathbf{w}$ that makes $L(\\mathbf{w})$ smallest: \n",
    "\n",
    "$$\n",
    "\\DeclareMathOperator*{\\argmin}{argmin}\n",
    "\\begin{aligned}\n",
    "\\hat{\\mathbf{w}} &= \\argmin_{\\mathbf{w}} L(\\mathbf{w})  \\\\ \n",
    "                 &= \\argmin_{\\mathbf{w}} \\frac{1}{n}\\sum_{i = 1}^n \\ell(s_i, y_i) \\\\ \n",
    "                 &= \\argmin_{\\mathbf{w}} \\frac{1}{n}\\sum_{i = 1}^n \\ell(\\langle \\mathbf{w}, \\mathbf{x}_i\\rangle, y_i)\\;.\n",
    "\\end{aligned}\n",
    "$${#eq-ERM}\n",
    "\n",
    ":::\n",
    ":::\n",
    "\n",
    "::: {.callout-note}\n",
    "::: {#prp-sum-of-convex}\n",
    "\n",
    "## Convex $\\ell$ means convex $L$\n",
    "\n",
    "If the per-observation loss function $\\ell:\\mathbb{R}\\times \\{0,1\\} \\rightarrow \\mathbb{R}$ is convex in its first argument, then the empirical risk $L(\\mathbf{w})$ is convex as a function of $\\mathbf{w}$. \n",
    "\n",
    ":::\n",
    ":::\n",
    "\n",
    "The proof of @prp-sum-of-convex involves some elementary properties of convex functions: \n",
    "\n",
    "1. If $f(\\mathbf{z})$ is convex as a function of $\\mathbf{z}$, then $g(\\mathbf{z}) = f(\\mathbf{A}\\mathbf{z'})$ is also convex as a function of $\\mathbf{z}'$, provided that all the dimensions work out. \n",
    "2. Any finite sum of convex functions is convex. \n",
    "\n",
    "So, we know that if we choose $\\ell$ to be convex in the score function, then the entire empirical risk $L$ will be convex as a function of the weight vector $\\mathbf{w}$. \n",
    "\n",
    "Why do we care? \n",
    "\n",
    "## Convex Functions Have  Global Minimizers\n",
    "\n",
    "We want to solve the empirical risk minimization problem: \n",
    "\n",
    "$$\n",
    "\\DeclareMathOperator*{\\argmin}{argmin}\n",
    "\\begin{aligned}\n",
    "\\hat{\\mathbf{w}} &= \\argmin_{\\mathbf{w}} L(\\mathbf{w}).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We might ask ourselves a few questions about this problem: \n",
    "\n",
    "1. **Existence**: Does there exist *any* choice of $\\mathbf{w}$ that achieves a minimizing value for this function? \n",
    "2. **Uniqueness**: Is this choice of $\\mathbf{w}$ unique, or are there multiple candidates?\n",
    "3. **Searchability**: are there algorithms which are guaranteed to (a) terminate and (b) not get \"trapped\" at a bad solution?\n",
    "\n",
    "Answering these questions precisely requires a bit more math: \n",
    "\n",
    "::: {.callout-note} \n",
    "::: {#def-minimizers} \n",
    "\n",
    "## Local and Global Minimizers\n",
    " \n",
    "A point $\\mathbf{z}\\in S$ is a *global minimizer* of the function $f:S \\rightarrow \\mathbb{R}$ if $f(\\mathbf{z}) \\leq f(\\mathbf{z}')$ for all $\\mathbf{z}' \\in S$. \n",
    "\n",
    "A point $\\mathbf{z} \\in S$ is a *local minimizer* of $f:S \\rightarrow \\mathbb{R}$ if there exists a neighborhood $T \\subseteq S$ containing $\\mathbf{z}$ such that $\\mathbf{z}$ is a global minimizer of $f$ on $T$. \n",
    "\n",
    ":::\n",
    ":::\n",
    "\n",
    "[It's ok if you don't know what it means for a set to be closed -- all the convex functions we will care about in this class will either be defined on sets where this theorem holds or will be otherwise defined so that the conclusions apply. \n",
    "]{.aside}\n",
    "\n",
    "::: {.callout-note} \n",
    "::: {#thm-convex-functions-are-nice}\n",
    "\n",
    "## Properties of Convex Functions\n",
    "\n",
    "Let $f:S \\rightarrow \\mathbb{R}$ be a convex function. Then: \n",
    "\n",
    "1. If $S$ is closed and bounded, $f$ has a minimizer $\\mathbf{z}^*$ in $S$. \n",
    "2. Furthermore, if $\\mathbf{z}^*$ is a *local* minimizer of $f$, then it is also a global minimizer. \n",
    "2. If in addition $f$ is *strictly* convex, then this minimizer is unique. \n",
    "\n",
    ":::\n",
    "::: \n",
    "\n",
    "::: {.proof} \n",
    "The proof of item 1 needs some tools from real analysis. The short version is: \n",
    "\n",
    "- Every convex function is *continuous*. \n",
    "- If $S\\subseteq \\mathbb{R}^n$ is closed and bounded, then it is *compact*. \n",
    "- Continuous functions achieve minimizers and maximizers on compact sets. \n",
    "\n",
    "It's ok if you didn't follow this! Fortunately the second part of the proof is one we can do together. Suppose to contradiction that $\\mathbf{z}^*$ is a local minimizer of $f$, but that there is also a point $\\mathbf{z}'$ such that $f(\\mathbf{z}') < f(\\mathbf{z}^*)$. Since $\\mathbf{z}^*$ is a local minimizer, we can find some neighborhood $T$ containing $\\mathbf{z}^*$ such that $\\mathbf{z}^*$ is a minimizer of $f$ on $T$. Let $\\lambda$ be some very small number and consider the point $\\mathbf{z} = \\lambda \\mathbf{z}' + (1-\\lambda)\\mathbf{z}^*$. Specifically, choose $\\lambda$ small enough so that $\\mathbf{z} \\in T$ (since this makes $\\mathbf{z}$ close to $\\mathbf{z}^*$). We can evaluate \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(\\mathbf{z}) &= f(\\lambda \\mathbf{z}' + (1-\\lambda)\\mathbf{z}^*) &\\quad \\text{(definition of $\\mathbf{z}$)}\\\\ \n",
    "       &\\leq \\lambda f(\\mathbf{z}') + (1-\\lambda)f(\\mathbf{z}^*)  &\\quad \\text{($f$ is convex)} \\\\ \n",
    "       &= f(\\mathbf{z}^*) + \\lambda (f(\\mathbf{z}') - f(\\mathbf{z}^*)) &\\quad \\text{(algebra)}\\\\ \n",
    "       &< f(\\mathbf{z}^*)\\;. &\\quad \\text{(assumption that $f(\\mathbf{z}') < f(\\mathbf{z}^*)$)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "But this is a contradiction, since we constructed $\\mathbf{z}$ to be in the neighborhood $T$ where $\\mathbf{z}^*$ is a local minimizer. We conclude that there is no  $\\mathbf{z}'$ such that $f(\\mathbf{z}') < f(\\mathbf{z}^*)$, and therefore that $\\mathbf{z}^*$ is a global minimizer. \n",
    "\n",
    "The proof of the third part follows a very similar argument to the proof of the second part.\n",
    ":::\n",
    "\n",
    "\n",
    "These properties of convex functions have very important implications for our fundamental questions on empirical risk minimization. If we choose a convex per-observation loss function $\\ell$, then our empirical risk $L$ will also be convex, and: \n",
    "\n",
    "\n",
    "\n",
    "**Existence**. The minimizer $\\hat{\\mathbf{w}} = \\argmin_{\\mathbf{w}}L(\\mathbf{w})$ will exist. \n",
    "\n",
    "**Uniqueness**: The minimizer $\\hat{\\mathbf{w}} = \\argmin_{\\mathbf{w}}L(\\mathbf{w})$ will be unique: if we run a minimization algorithm repeatedly, we'll get the same answer every time. \n",
    "\n",
    "**Searchability**: When $L$ is convex, there are also no local minimizers other than the global minimizer. Algorithmically, ***this is the most important property of convexity***. It means that if I manage to find any local minimizer at all, that point *must* be the global minimizer. \n",
    "[If you've taken an algorithms class, one way of thinking of convexity is that it guarantees that *greedy methods work* for solving minimization problems.]{.aside}\n",
    "**Performance**: Convexity significantly reduces the difficulty of our task: instead of trying to find \"the best\" solution, it's sufficient for us to find any local optimum. This means that we can design our algorithms to be \"greedy local minimizer hunters.\" There are lots of fast algorithms to do this. An especially important class of algorithms are *gradient descent methods*, which we'll discuss soon. \n",
    "\n",
    "\n",
    "## Demo: Logistic Regression\n",
    "\n",
    "You may have heard of *logistic regression* in a course on statistics or data science. Logistic regression is simply binary classification using the binary cross-entropy loss function which we saw above: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ell(s, y) &=  -y \\log \\sigma(s) - (1-y)\\log (1-\\sigma(s))\\;,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "As can be proven with calculus, this function is convex as a function of $s$. The logistic regression problem then becomes the problem of solving: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{\\mathbf{w}} &= \\argmin_\\mathbf{w} \\frac{1}{n} \\sum_{i = 1}^n \\ell(s_i, y_i)  \\\\ \n",
    "&= \\argmin_\\mathbf{w} \\frac{1}{n} \\sum_{i = 1}^n \\left[-y_i \\log \\sigma(s_i) - (1-y_i)\\log (1-\\sigma(s_i))\\right] \\\\ \n",
    "&= \\argmin_\\mathbf{w} \\frac{1}{n} \\sum_{i = 1}^n \\left[-y_i \\log \\sigma(\\langle \\mathbf{w}, \\mathbf{x}_i \\rangle) - (1-y_i)\\log (1-\\sigma(\\langle \\mathbf{w}, \\mathbf{x}_i \\rangle)\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "So, let's do convex empirical risk minimization! We'll use the following data set. Note that this data is not linearly separable and therefore the perceptron algorithm would not converge. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d139f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: 'Data for logistic regression.'\n",
    "#| fig-cap-location: margin\n",
    "#| label: fig-LR-data\n",
    "#| code-fold: true\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "X, y = classification_data(noise = 0.5)\n",
    "plot_classification_data(X, y, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "48bc11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's go ahead and train a logistic regression model. For the purposes of today, we can do this in a very simple way that doesn't even involve an explicit training loop. Next time, we'll learn how to write an explicit training loop. \n",
    "\n",
    "First, we'll define a complete function for calculating the empirical risk for a given value of $\\mathbf{w}$. Since we already implemented `binary_cross_entropy`, this implementation is very quick: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b9dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "c48a8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we'll use the `minimize` function from `scipy.optimize` to find the value of $\\mathbf{w}$ that makes this function smallest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de84042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Learned parameter vector w = {w}.\\nThe empirical risk is {result.fun:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "e49b4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "How does it look? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6befb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: 'The separating line learned by logistic regression.'\n",
    "#| fig-cap-location: margin\n",
    "#| label: fig-LR-line\n",
    "#| code-fold: true\n",
    "\n",
    "def draw_line(w, X, y, x_min, x_max, ax, **kwargs):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plot_classification_data(X, y, ax)\n",
    "    x = torch.linspace(x_min, x_max, 101)\n",
    "    y = -(w[0]*x + w[2])/w[1]\n",
    "    l = ax.plot(x, y, **kwargs)\n",
    "\n",
    "draw_line(w, X, y, x_min = -0.5, x_max = 1.5, ax = ax, color = \"black\", linestyle = \"dashed\")\n",
    "\n",
    "# fig"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "bad84047",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pretty good! Yes, it's as easy as that -- provided that you don't ask too many questions about how the `minimize` function works. Questions like that will be the topic of our next several sets of notes. \n",
    "\n",
    "## Recap\n",
    "\n",
    "In this set of notes, we introduced a fundamental idea: *convex empirical risk minimization*. To do convex empirical risk minimization, all we need is a convex per-observation loss function. This gives us a *convex empirical risk function*, which is simply the mean of all the per-observation losses. Once we have that, the problem of classification reduces to the problem of finding a value of the parameter vector $\\mathbf{w}$ that makes the empirical risk small. Convexity guarantees that this problem has exactly one solution. Today, we found this solution using a packaged optimizer. Starting next time, we'll learn how to write our own optimization algorithms and explore how optimization techniques enable scalable machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "0377b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### (Optional): A Logistic Regression Training Loop\n",
    "\n",
    "How would we do this if we didn't have access to the `minimize` function? We'll soon discuss this question much more. For now, we can take a look at the code block below, which implements such a loop using a framework very similar to the one we learned for perceptron. This model *also* inherits from the `LinearModel` class that you previously started implementing. The training loop is also *very* similar to our training loop for the perceptron. The main difference is that the loss is calculated using the `binary_cross_entropy` function above, and the `step` function of the `GradientDescentOptimizer` works differently in a way that we will discuss in the following section. \n",
    "\n",
    "*Starting with the code block below, you won't be able to follow along in coding these notes unless you have sneakily implemented logistic regression in a `hidden` module.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ddb1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-cap: 'Evolution of the binary cross entropy loss function in the logistic regression training loop.'\n",
    "#| fig-cap-location: margin\n",
    "#| label: fig-LR-loss-iterations\n",
    "\n",
    "from hidden.logistic import LogisticRegression, GradientDescentOptimizer\n",
    "\n",
    "# instantiate a model and an optimizer\n",
    "LR = LogisticRegression() \n",
    "opt = GradientDescentOptimizer(LR)\n",
    "\n",
    "# for keeping track of loss values\n",
    "loss_vec = []\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    # not part of the update: just for tracking our progress    \n",
    "    loss = LR.loss(X, y) \n",
    "    loss_vec.append(loss)\n",
    "\n",
    "    # only this line actually changes the parameter value\n",
    "    opt.step(X, y, lr = 0.02)\n",
    "\n",
    "plt.plot(torch.arange(1, len(loss_vec)+1), loss_vec, color = \"black\")\n",
    "plt.semilogx()\n",
    "labs = plt.gca().set(xlabel = \"Number of gradient descent iterations\", ylabel = \"Loss (binary cross entropy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "485e8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "The loss quickly levels out to a constant value (which is the same as we learned with `scipy.optimize.minimize`). Because our theory tells us that the loss function is convex, we know that the value of $\\mathbf{w}$ we have found is the best possible, in the sense of minimizing the loss. \n",
    "\n",
    "Let's take a look at the separating line we found: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_line(LR.w, X, y, x_min = -0.5, x_max = 1.5, ax = ax, color = \"black\", linestyle = \"dashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "095d2b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yep, that's the same line as we found earlier! \n",
    "\n",
    "Although our data is not linearly separable, the separating line we have learned appears to do a reasonable job of separating the points from each other. Let's check our accuracy: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a03bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "450efa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Not too bad! In the next section, we'll learn much, much more about what's behind that `opt.step()` call. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
